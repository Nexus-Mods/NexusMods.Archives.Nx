{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"The Nexus (.nx) Archive Format      A Quite OK Archive Format.          For Storing and Sharing Mods."},{"location":"#about","title":"About","text":"<p>The Nexus (<code>.nx</code>) format is a semi-SOLID archive format, using modern compression technologies such as ZStandard and LZ4 under the hood.</p> <pre><code>flowchart TD\n    subgraph Block 2\n        BigFile1.bin\n    end\n\n    subgraph Block 1\n        BigFile0.bin\n    end\n\n    subgraph Block 0\n        ModConfig.json -.-&gt; Updates.json \n        Updates.json -.-&gt; more[\"... more .json files\"]        \n    end</code></pre> <p>Between size optimized SOLID archives like <code>.7z</code> w/ <code>LZMA</code> and non-SOLID archives like <code>.zip</code> w/ <code>Deflate</code>, the Nexus  (<code>.nx</code>) format bridges the gap; providing a tradeoff with most of the benefit of both worlds.</p> <p>We aim to create a simple format, appropriate for both local storage of mods and for downloading from the web. By using modern compression techniques, we provide both competitive file size and compression speeds.  </p>"},{"location":"#motivation","title":"Motivation","text":"<p>For the Nexus App</p> <p>We recompress legacy uploaded mods for faster deployment and re-deployment. And can skip hashing after downloading a <code>.nx</code> file.  </p> <p>For the Community</p> <p>We can get cool tech in the hands of people; and contribute back to the open source community.</p> <ul> <li>For Fast Random Access</li> </ul> <p>We use small SOLID blocks, for grouping small files where SOLID compression matters the most. Combine with blazing fast 5000+MB/s (modern CPU) single core LZ4 for pretty decent random access speeds.  </p> <ul> <li>For Storage Sizes</li> </ul> <p>For longer term archival and smaller downloads; bigger files are handled by ZStandard to reduce total size. You probably don't need to preview them instantly, so it makes sense, right?  </p> <ul> <li>For File Downloads</li> </ul> <p>This format allows us to do partial downloads of mods. If only a few files in a mod were updated; why should you need to download the entire thing again?  </p>"},{"location":"#technical-questions","title":"Technical Questions","text":"<p>If you have technical questions, direct them to library &amp; docs author @Sewer56  via one of these methods:  </p> <ul> <li>Nexus Discord </li> <li>Open an Issue </li> </ul> <p>Happy Hacking \ud83e\udde1</p>"},{"location":"Benchmarks/","title":"Benchmarks","text":"<p>Coming Soon (TM)</p> <p>Spoiler: This bottlenecks any NVMe \ud83d\ude00</p> <p>Info</p> <p>All tests were executed in the following environment: - <code>Library Version</code>: 0.3.0-preview (17th May 2023) - <code>zstd version</code>: 1.5.2 (MSVC) - <code>lz4 version</code>: K4os.Compression.LZ4 1.3.5 - <code>CPU</code>: AMD Ryzen 9 5900X (12C/24T) - <code>RAM</code>: 32GB DDR4-3000 (16-17-17-35) - <code>OS</code>: Windows 11 22H2 (Build 22621) - <code>Storage</code>: Samsung 980 Pro 1TB (NVMe) [PCI-E 3.0 x4]  </p>"},{"location":"Benchmarks/#common-data-sets","title":"Common Data Sets","text":"<p>These are the data sets which are used in multiple benchmarks below.</p>"},{"location":"Benchmarks/#textures","title":"Textures","text":"<p>Test Data: Skyrim 202X 8.6 Update</p> <p>This dataset primarily consists of mostly DDS BC7 textures, with max dimension of <code>*1024</code> to <code>*8192</code> with a total size of 2.11GB</p> <p>Texture overhauls in games make a majority of mods which large file sizes out there. Therefore, having a good compression ratio on this data set is important.  </p>"},{"location":"Benchmarks/#log-files","title":"Log Files","text":"<p>Available Here</p> <p>This dataset consists of 189 Reloaded-II Logs from end users, across various games, with a total size of 12.4MiB</p>"},{"location":"Benchmarks/#lightly-compressed-files","title":"Lightly Compressed Files","text":"<p>This dataset consists of every <code>.one</code> archive from the 2004 Release of Sonic Heroes, with non-English files removed (168 MiB total).</p> <p>Sometimes mods have to ship using games' native compression and/or formats; in which case, they are not very highly compressible, as the data is already compressed.  </p> <p>Many older games and some remasters of older games, use custom compression. This compression is usually some variant of basic LZ77. In this case, we test on data compressed using SEGA's PRS Compression Scheme, based on LZ77 with Run Length Encoding [RLE]. This was a common compression scheme in many SEGA games over ~15 or so years.  </p> <p>This data set was thrown in as a bonus, to see what happens!</p>"},{"location":"Benchmarks/#block-size-logs","title":"Block Size (Logs)","text":"<p>Investigates the effect of block size on large files with repeating patterns.</p> <p>Test Data: Log Files</p> <p>This test was not in-memory, thus throughput is limited by NVMe bottlenecks. Throughput is provided for reference only.</p>"},{"location":"Benchmarks/#zstandard-only","title":"ZStandard Only","text":"<p>Applied level applies to both <code>chunked</code> and <code>solid</code> compression levels.</p> Level Block Size Size Ratio (Size) Throughput Ratio (Throughput) -1 32767 1,150,976 1.778 239.74MiB/s 1.944 -1 65535 1,077,248 1.665 226.90MiB/s 1.839 -1 131071 970,752 1.500 215.36MiB/s 1.746 -1 262143 872,448 1.348 186.86MiB/s 1.515 -1 524287 770,048 1.190 169.42MiB/s 1.373 -1 1048575 708,608 1.095 153.09MiB/s 1.241 -1 2097151 667,648 1.032 153.09MiB/s 1.241 -1 4194303 659,456 1.019 136.63MiB/s 1.107 -1 8388607 647,168 1.000 123.36MiB/s 1.000 Level Block Size Size Ratio (Size) Throughput Ratio (Throughput) 9 32767 909,312 2.220 204.94MiB/s 2.032 9 65535 819,200 2.001 192.52MiB/s 1.908 9 131071 733,184 1.790 186.86MiB/s 1.852 9 262143 630,784 1.541 181.52MiB/s 1.800 9 524287 548,864 1.340 167.19MiB/s 1.658 9 1048575 495,616 1.210 156.87MiB/s 1.556 9 2097151 442,368 1.080 149.49MiB/s 1.482 9 4194303 413,696 1.010 127.06MiB/s 1.259 9 8388607 409,600 1.000 100.84MiB/s 1.000 Level Block Size Size Ratio (Size) Throughput Ratio (Throughput) 16 32767 884,736 2.180 71.38MiB/s 2.754 16 65535 790,528 1.949 69.43MiB/s 2.677 16 131071 712,704 1.756 64.50MiB/s 2.486 16 262143 598,016 1.474 52.72MiB/s 2.034 16 524287 548,864 1.353 90.12MiB/s 3.476 16 1048575 491,520 1.212 76.09MiB/s 2.934 16 2097151 442,368 1.091 64.50MiB/s 2.486 16 4194303 413,696 1.020 44.27MiB/s 1.708 16 8388607 405,504 1.000 25.93MiB/s 1.000 <p>Level 16 doesn't yield much improvement; lower levels are already good with repeating data.</p> Level Block Size Size Ratio (Size) Throughput Ratio (Throughput) 22 131071 696,320 2.072 15.55MiB/s 3.945 22 524287 512,000 1.525 17.97MiB/s 4.561 22 1048575 438,272 1.305 18.23MiB/s 4.626 22 8388607 335,872 1.000 3.94MiB/s 1.000 <p>Level 22 excels at large blocks due to larger window size, but that's too slow.</p>"},{"location":"Benchmarks/#lz4-only","title":"LZ4 Only","text":"Level Block Size Size Ratio (Size) Throughput Ratio (Throughput) 12 32767 1,159,168 1.490 158.83MiB/s 4.326 12 65535 1,069,056 1.373 153.09MiB/s 4.169 12 131071 983,040 1.263 138.11MiB/s 3.764 12 262143 913,408 1.174 125.81MiB/s 3.428 12 524287 839,680 1.079 112.45MiB/s 3.064 12 1048575 806,912 1.037 116.57MiB/s 3.176 12 2097151 786,432 1.011 92.75MiB/s 2.526 12 4194303 786,432 1.011 68.31MiB/s 1.860 12 8388607 778,240 1.000 36.72MiB/s 1.000"},{"location":"Benchmarks/#block-size-recompressed-files","title":"Block Size (Recompressed Files)","text":"<p>Investigates the effect of block size on already lightly compressed data (w/ uncompressed headers).</p> <p>Test Data: Lightly Compressed Files</p> <p>This test was not in-memory, thus throughput may be subject to NVMe bottlenecks.</p> <p>ZStd 1.5.4 and above have large improvements for uncompressible data handling performance; but only 1.5.2 was available at time of testing.</p>"},{"location":"Benchmarks/#zstandard-only_1","title":"ZStandard Only","text":"Level Block Size Size Ratio (Size) Throughput Ratio (Throughput) 9 32767 139,653,120 1.355 163.88MiB/s 1.068 9 65535 139,575,296 1.354 163.77MiB/s 1.068 9 262143 136,527,872 1.321 162.61MiB/s 1.060 9 524287 135,581,696 1.314 160.95MiB/s 1.049 9 1048575 129,404,928 1.253 153.41MiB/s 1.000 9 2097151 122,429,440 1.186 174.43MiB/s 1.137 9 4194303 113,074,176 1.092 193.88MiB/s 1.264 9 8388607 105,893,888 1.000 209.17MiB/s 1.363 Level Block Size Size Ratio (Size) Throughput Ratio (Throughput) 16 32767 137,244,672 1.323 103.38MiB/s 1.064 16 262143 134,094,848 1.291 102.71MiB/s 1.058 16 1048575 127,381,504 1.227 99.98MiB/s 1.029 16 4194303 111,185,920 1.071 102.58MiB/s 1.056 16 8388607 103,788,544 1.000 97.13MiB/s 1.000 Level Block Size Size Throughput -1 8388607 154,382,336 1297.30MiB/s <p>It seems ZStd can improve on existing LZ77-only compression schemes, in cases where Huffman coding is available.  </p> <p>This is why only levels <code>&gt; -1</code> show improvement.  </p>"},{"location":"Benchmarks/#lz4-only_1","title":"LZ4 Only","text":"Level Block Size Size Ratio (Size) Throughput Ratio (Throughput) 12 32767 155,537,408 1.021 319.52MiB/s 1.146 12 262143 153,378,816 1.007 340.32MiB/s 1.221 12 1048575 152,670,208 1.003 371.06MiB/s 1.331 12 4194303 152,317,952 1.000 343.02MiB/s 1.231 12 8388607 152,264,704 1.000 278.74MiB/s 1.000"},{"location":"Benchmarks/#chunk-size-textures","title":"Chunk Size (Textures)","text":"<p>Investigates the effect of chunk size on large, well compressible files.</p> <p>Test Data: Texture</p>"},{"location":"Benchmarks/#zstandard-only_2","title":"ZStandard Only","text":"<p>Note: Due to intricacies of ZStd, Chunk Size 1MiB is left out from results as it produces the same output as 4MiB.</p> Level Chunk Size Size Ratio (Size) Throughput Ratio (Throughput) -1 4194304 2,211,012,608 1.0003 1554.50MiB/s 1.000 -1 8388608 2,210,525,184 1.0001 1738.17MiB/s 1.118 -1 16777216 2,210,295,808 1.000 1900.24MiB/s 1.222 Level Chunk Size Size Ratio (Size) Throughput Ratio (Throughput) 9 4194304 1,802,686,464 1.009 142.77MiB/s 1.061 9 8388608 1,791,832,064 1.003 134.58MiB/s 1.000 9 16777216 1,786,757,120 1.000 143.72MiB/s 1.068 Level Chunk Size Size Ratio (Size) Throughput Ratio (Throughput) 16 4194304 1,784,340,480 1.014 73.38MiB/s 1.233 16 8388608 1,767,153,664 1.005 66.71MiB/s 1.121 16 16777216 1,759,150,080 1.000 59.52MiB/s 1.000 Level Chunk Size Size Ratio (Size) Throughput Ratio (Throughput) 22 4194304 1,769,832,448 1.023 50.76MiB/s 1.565 22 8388608 1,747,853,312 1.010 42.33MiB/s 1.304 22 16777216 1,730,514,944 1.000 32.45MiB/s 1.000"},{"location":"Benchmarks/#lz4-only_2","title":"LZ4 Only","text":"<p>LZ4 will have some niche applications; this is one of them. Fast texture loading.</p> Level Chunk Size Size Ratio (Size) Throughput Ratio (Throughput) 12 4194304 2,013,491,200 1.001 364.04MiB/s 1.103 12 8388608 2,012,303,360 1.000 357.71MiB/s 1.084 12 16777216 2,011,750,400 1.000 330.12MiB/s 1.000 <p>LZ4 does a huge sacrifice of file size for decompression speeds. Depending on use case; this might be okay, but for longer term archiving ZStd Level 9+ is preferred.  </p>"},{"location":"Benchmarks/#thread-scaling-packing","title":"Thread Scaling: Packing","text":"<p>Test Data: Texture</p> <p>Files were packed with 16MB Chunk Size, Chunk Size did not seem to have an effect on compression speed.</p>"},{"location":"Benchmarks/#zstandard-only_3","title":"ZStandard Only","text":"<p>Packing Speed with ZStd Only, Compression Level</p> <p>Native ZStd library used, speeds are within margin of error on all runtimes.</p> Level Thread Count Throughput Ratio (Throughput) -1 1 567.11MiB/s 1.000 -1 2 904.47MiB/s 1.595 -1 3 1190.45MiB/s 2.099 -1 4 1308.24MiB/s 2.306 <p>I (Sewer) cannot test more than 4 threads on my system due to I/O bottlenecks, but I expect the scaling to continue linearly.</p> Level Thread Count Throughput Ratio (Throughput) 9 1 60.22MiB/s 1.00 9 2 92.33MiB/s 1.53 9 3 117.53MiB/s 1.95 9 4 134.76MiB/s 2.24 9 8 179.55MiB/s 2.98 9 12 172.57MiB/s 2.86 9 24 (SMT) 142.57MiB/s 2.37 Level Thread Count Throughput Ratio (Throughput) 16 1 8.79MiB/s 1.00 16 2 13.49MiB/s 1.53 16 3 18.70MiB/s 2.13 16 4 22.45MiB/s 2.56 16 8 37.25MiB/s 4.24 16 12 46.25MiB/s 5.26 16 24 (SMT) 59.71MiB/s 6.79"},{"location":"Benchmarks/#lz4-only_3","title":"LZ4 Only","text":"<p>Packing Speed with LZ4 Only, Compression Level 12</p> Thread Count Throughput Ratio (Throughput) 1 32.00 MiB/s 1.00 2 52.94 MiB/s 1.65 3 82.22 MiB/s 2.57 4 102.72 MiB/s 3.21 8 192.76 MiB/s 6.02 12 256.30 MiB/s 8.01 24 (SMT) 346.98 MiB/s 10.84 <p>Scaling for LZ4 is mostly linear with real core count.</p>"},{"location":"Benchmarks/#thread-scaling-extraction","title":"Thread Scaling: Extraction","text":"<p>All benchmarks under this section are in-memory; due to exceeding speeds achievable by consumer grade NVMe.</p> <p>Due to the layout of archive format; the nature of test data (i.e. many small files vs big files) has no effect on performance. (Outside of the standard FileSystem/Storage inefficiencies if writing many small files to disk).</p> <p>Test Data: Texture</p> <p>Some reference speeds:</p> Compression Method Speed memcpy ~16.62 GiB/s lz4 1.9.2 (native), 1 thread, [lzbench] ~4.204 GiB/s"},{"location":"Benchmarks/#zstandard-only_4","title":"ZStandard Only","text":"<p>Decompression Speed when Extracting with ZStandard Only</p> <p>Files were packed with 16MB Chunk Size, and ZStd Level 16</p> <p>Native ZStd library used, speeds are within margin of error on all runtimes.</p> <p>.NET 7 / 8 Preview 3</p> Thread Count Speed 1 ~1.01 GiB/s 2 ~1.99 GiB/s 3 ~2.87 GiB/s 4 ~3.70 GiB/s 6 ~5.15 GiB/s 8 ~6.35 GiB/s 10 ~7.38 GiB/s 12 ~7.81 GiB/s 24 ~7.19 GiB/s \u203c\ufe0f <p>Observed dropoff with hyperthreading, presumably due to cache inefficiency. Ideally we could detect real core count; but this is hard; it is deliberately abstracted.</p>"},{"location":"Benchmarks/#lz4-only_4","title":"LZ4 Only","text":"<p>Decompression Speed when Extracting with LZ4 Only</p> <p>Files were packed with 16MB Chunk Size, and LZ4 Level 12</p> <p>.NET 7</p> Thread Count Speed 1 ~2.83 GiB/s 2 ~5.56 GiB/s 3 ~8.09 GiB/s 4 ~10.00 GiB/s 6+ ~11.63 GiB/s <p>.NET 8 Preview 3</p> Thread Count Speed 1 ~3.82 GiB/s 2 ~7.36 GiB/s 3 ~10.41 GiB/s 4+ ~11.72 GiB/s 8+ ~12.10 GiB/s <p>.NET 8 Preview 3 NativeAOT</p> Thread Count Speed 1 ~3.26 GiB/s 2 ~6.33 GiB/s 3 ~9.20 GiB/s 4 ~11.09 GiB/s 6+ ~11.93 GiB/s"},{"location":"Benchmarks/#presets","title":"Presets","text":"<p>The following presets have been created...</p>"},{"location":"Benchmarks/#fastrandom-access-preset","title":"Fast/Random Access Preset","text":"<p>This preset is designed for optimising random access, and intended in use when low latency previews are needed such as in the Nexus App.</p> <ul> <li><code>Solid Algorithm: ZStandard</code> </li> <li><code>Chunked Algorithm: ZStandard</code> </li> <li><code>Solid Compression Level: -1</code> </li> <li><code>Chunked Compression Level: 9</code> </li> </ul>"},{"location":"Benchmarks/#archivalupload-preset","title":"Archival/Upload Preset","text":"<p>This preset is designed for all other use cases. Providing a fair balance for all other use cases.</p> <ul> <li><code>Solid Algorithm: ZStandard</code> </li> <li><code>Chunked Algorithm: ZStandard</code> </li> <li><code>Solid Compression Level: 16</code> </li> <li><code>Chunked Compression Level: 9</code> </li> </ul>"},{"location":"Benchmarks/#comparison-to-common-archiving-solutions","title":"Comparison to Common Archiving Solutions","text":"<p>Tests here were ran on .NET 8 Preview 3 NativeAOT, there aren't currently any significant differences here between runtimes.</p> <p>All tests were ran under optimal thread count/best case scenario.</p> <p>NX is entirely I/O bottlenecked here (on PCI-E 3.0 drive). Therefore in-memory benchmarks are also provided.</p>"},{"location":"Benchmarks/#compression-scripts","title":"Compression Scripts","text":"<p>Zip (Maximum): <pre><code>\"7z.exe\" a -tzip -mtp=0 -mm=Deflate -mmt=on -mx7 -mfb=64 -mpass=3 -bb0 -bse0 -bsp2 -mtc=on -mta=on \"output\" \"input\" \n</code></pre></p> <p>Zip (Maximum, Optimized): <pre><code>\"7z.exe\" a -tzip -mtp=0 -mm=Deflate -mmt=on -mx7 -mfb=64 -mpass=1 -bb0 -bse0 -bsp2 -mtc=on -mta=on \"output\" \"input\" \n</code></pre></p> <p>7z (Normal): <pre><code>7z.exe\" a -t7z -m0=LZMA2 -mmt=on -mx5 -md=16m -mfb=32 -ms=4g -mqs=on -sccUTF-8 -bb0 -bse0 -bsp2 -mtc=on -mta=on \"output\" \"input\" \n</code></pre></p> <p>7z (Ultra): <pre><code>7z.exe\" a -t7z -m0=LZMA2 -mmt=on -mx9 -md=64m -mfb=64 -ms=16g -mqs=on -sccUTF-8 -bb0 -bse0 -bsp2 -mtc=on -mta=on \"output\" \"input\" \n</code></pre></p> <p>Nx (Archival Preset): <pre><code>NexusMods.Archives.Nx.Cli.exe pack --source \"input\" --target \"output\" --solid-algorithm ZStandard --chunked-algorithm ZStandard --solidlevel 16 --chunkedlevel 9\n</code></pre></p> <p>Nx (Random Access Preset): <pre><code>NexusMods.Archives.Nx.Cli.exe pack --source \"input\" --target \"output\" --solid-algorithm ZStandard --chunked-algorithm ZStandard --solidlevel -1 --chunkedlevel 9\n</code></pre></p> <p>Zip (Optimized) cannot be set via GUI, only via CMD parameter.</p>"},{"location":"Benchmarks/#unpacking-scripts","title":"Unpacking Scripts","text":"<p>7z/Zip: <pre><code>7z.exe\" x -aos \"-ooutput\" -bb0 -bse0 -bsp2 -pdefault -sccUTF-8 -snz \"input\"\n</code></pre></p> <p>Nx:  </p> <pre><code>./NexusMods.Archives.Nx.Cli.exe extract --source input --target \"output\"\n</code></pre>"},{"location":"Benchmarks/#textures_1","title":"Textures","text":"<p>Test Data: Texture</p> <p>Packing:  </p> Method Time Taken Ratio (Time) Size Ratio (Size) Zip (Maximum) 17.385s 2.34 1,957,310,894 1.24 Zip (Optimized) 7.443s 1.00 1,961,872,315 1.25 7z (Normal) 73.572s 9.88 1,616,082,220 1.03 7z (Ultra) 120.746s 16.23 1,570,741,070 1.00 Nx (Random Access, 12T) 12.909s 1.73 1,787,568,128 1.14 Nx (Archival, 12T) 12.955s 1.74 1,786,634,240 1.14 <p>Unpacking: </p> Method Time Taken Ratio (Time) Zip 13.857s 50.76 7z (Ultra) 6.238s 22.86 7z (Normal) 3.705s 13.57 Nx (12T) 1.172s 4.29 Nx [In-Memory] (12T) 0.273s 1.00"},{"location":"Benchmarks/#logs","title":"Logs","text":"<p>Packing:</p> Method Time Taken Ratio (Time) Size Ratio (Size) Zip (Maximum) 0.149s 2.07 758,928 2.18 Zip (Optimized) 0.115s 1.60 768,374 2.21 7z (Normal) 0.297s 4.13 378,780 1.09 7z (Ultra) 0.545s 7.57 347,574 1.00 Nx (Archival, 12T) 0.194s 2.69 491,520 1.41 Nx (Random Access, 12T) 0.072s 1.00 708,608 2.04 <p>Unpacking:</p> Method Time Taken Ratio (Time) Zip 0.214s 167.19 7z (Ultra) 0.225s 175.78 7z (Normal) 0.267s 208.59 Nx (Random Access) 0.127s 99.22 Nx (Archival) 0.127s 99.22 Nx (Random Access) [In-Memory] (1T) 0.00304s 2.38 Nx (Archival) [In-Memory] (1T) 0.00300s 2.34 Nx (Random Access) [In-Memory] (4T) 0.0016s 1.25 Nx (Archival) [In-Memory] (4T) 0.00128s 1.00 <p>Extraction is I/O bottlenecked; Windows is slow to create small files.</p> <p>Random Access mode is not faster here due to nature of data set. For larger compressed blocks however, it achieves ~3.5x speed.</p>"},{"location":"Contributing-Locally/","title":"Contributing to the Wiki: Locally","text":""},{"location":"Contributing-Locally/#tutorial","title":"Tutorial","text":"<p>You should learn the basics of <code>git</code>, an easy way is to give GitHub Desktop (Tutorial) a go. It's only 15 minutes \ud83d\ude00.</p> <ol> <li>Create a GitHub account.</li> <li> <p>Fork this repository:</p> <p></p> <p>This will create a copy of the repository on your own user account, which you will be able to edit.</p> </li> <li> <p>Clone this repository.</p> <p>For example, using GitHub Desktop: </p> </li> <li> <p>Make changes inside the <code>docs</code> folder.</p> <p></p> <p>Consider using a Markdown Cheat Sheet if you are new to markdown.</p> <p>I recommend using a markdown editor such as <code>Typora</code>. Personally I just work from inside <code>Rider</code>.  </p> </li> <li> <p>Commit the changes and push to GitHub.</p> </li> <li> <p>Open a <code>Pull Request</code>.</p> <p></p> <p>Opening a <code>Pull Request</code> will allow us to review your changes before adding them with the main official page. If everything's good, we'll hit the merge button and add your changes to the official repository.</p> </li> </ol>"},{"location":"Contributing-Locally/#website-live-preview","title":"Website Live Preview","text":"<p>If you are working on the wiki locally, you can generate a live preview the full website. Here's a quick guide of how you could do it from your <code>command prompt</code> (cmd).</p> <ol> <li> <p>Install Python 3</p> <p>If you have <code>winget</code> installed, or Windows 11, you can do this from the command prompt. <pre><code>winget install Python.Python.3\n</code></pre></p> <p>Otherwise download Python 3 from the official website or package manager.</p> </li> <li> <p>Install Material for MkDocs and Plugins (Python package)     <pre><code># Restart your command prompt before running this command.\npip install mkdocs-material\npip install mkdocs-redirects\n</code></pre></p> </li> <li> <p>Open a command prompt in the folder containing <code>mkdocs.yml</code>. and run the site locally.     <pre><code># Move to project folder.\ncd &lt;Replace this with full path to folder containing `mkdocs.yml`&gt;\nmkdocs serve\n</code></pre></p> <p></p> <p>Copy the address to your web browser and enjoy the live preview; any changes you save will be shown instantly.</p> </li> </ol>"},{"location":"Contributing/","title":"Contributing","text":"<p>Info</p> <p>Some useful guidance for anyone wishing to contribute to library.</p>"},{"location":"Contributing/#public-api-analyzer","title":"Public API Analyzer","text":"<p>Tip</p> <p>This project uses Public API Analyzer to ensure API stability. Before submitting a PR, please fix any analyzer warnings created by adding new APIs.</p> <p>Note: The analyzer quick fix only fixes it for one target framework. For convenience, a <code>Powershell</code> script <code>FixUndeclaredAPIs.ps1</code> is included in repo root to work around this.  </p>"},{"location":"Contributing/#rider-bug-tests-not-recompiled-after-main-library-changes","title":"Rider Bug: Tests not Recompiled After Main Library Changes","text":"<p>Failure</p> <p>In some cases, making changes to the main library will not correctly trigger recompilation of test project; leading you to debug old code. This happens in 2023.1.1; unsure if affects other versions. Make sure to hit <code>Ctrl+Shift+B</code> to  force a recompliation of whole project just in case.</p>"},{"location":"Usage/","title":"Usage","text":""},{"location":"Usage/#high-level-api","title":"High Level API","text":"<p>Info</p> <p>The recommended way to use the library is through the high level Fluent API.</p>"},{"location":"Usage/#packing","title":"Packing","text":"<p>Use the <code>NxPackerBuilder</code> API to fluently create a new archive.</p> <pre><code>var builder = new NxPackerBuilder();\nbuilder.AddFolder(source);\nbuilder.WithOutput(new FileStream(target, FileMode.Create, FileAccess.ReadWrite));\n\n// Set some settings\nif (blocksize.HasValue) builder.WithBlockSize(blocksize.Value);\nif (chunksize.HasValue) builder.WithBlockSize(chunksize.Value);\nif (solidLevel.HasValue) builder.WithSolidCompressionLevel(solidLevel.Value);\nif (chunkedLevel.HasValue) builder.WithChunkedLevel(chunkedLevel.Value);\nif (solidAlgorithm.HasValue) builder.WithSolidBlockAlgorithm(solidAlgorithm.Value);\nif (chunkedAlgorithm.HasValue) builder.WithSolidBlockAlgorithm(chunkedAlgorithm.Value);\nif (threads.HasValue) builder.WithMaxNumThreads(threads.Value);\n\n// Make the Archive\nbuilder.Build(); // Blocking\n</code></pre>"},{"location":"Usage/#unpacking","title":"Unpacking","text":"<p>Use the <code>NxUnpackerBuilder</code> API to fluently extract an archive.</p> <pre><code>// Make the builder.\nvar stream = new FileStream(source, FileMode.Open, FileAccess.Read);\nvar builder = new NxUnpackerBuilder(new FromStreamProvider(stream));\n\n// Output all files to disk.\nbuilder.AddFilesWithDiskOutput(builder.GetFileEntriesRaw(), outputDirectory);\n\nif (threads.HasValue)\nbuilder.WithMaxNumThreads(threads.Value);\n\n// Extract the archive.\nbuilder.Extract(); // Blocking\n</code></pre>"},{"location":"Usage/#mid-level-api","title":"Mid Level API","text":"<p>Info</p> <p>Lower level API is for those who want to get more control over the packing process.</p>"},{"location":"Usage/#packing_1","title":"Packing","text":"<p>For packing archives, use the <code>NxPacker.Pack</code> API.</p> <p>Example:</p> <pre><code>using var output = File.Create(\"archive.nx\");\nvar settings = new PackerSettings { Output = output };\nvar files = FileFinder.GetFiles(\"some/folder/path\");\nNxPacker.Pack(files, settings);\n</code></pre> <p>In this example, we get the files to pack from a directory using the <code>FileFinder</code> API, specify the settings using <code>PackerSettings</code>  and then call <code>NxPacker.Pack</code> to pack the files.</p> <p>The files parameter is of type <code>PackerFile[]</code>, which has the following interface.</p> <pre><code>public class PackerFile : IHasRelativePath, IHasFileSize, IHasSolidType, IHasCompressionPreference, ICanProvideFileData\n{\n// IFileDataProvider(s) are provided in NexusMods.Archives.Nx.FileProviders namespace !!\n// They use names called `FromXXXProvider` where XXX is the source.\npublic required IFileDataProvider FileDataProvider { get; init; }\npublic string RelativePath { get; init; } = string.Empty;\npublic long FileSize { get; init; }\n\n// Only honoured if SolidType == NoSolid\npublic CompressionPreference CompressionPreference { get; set; } = CompressionPreference.NoPreference;\npublic SolidPreference SolidType { get; set; } = SolidPreference.Default;\n}\n</code></pre> <p>This allows you more granular control of where the data to be compressed is sourced from, for example you can create a file to be packed from an array in memory by doing the following:  </p> <pre><code>return new PackerFile()\n{\nFileSize = fileSize,\nRelativePath = $\"SomeCoolFile\",\nFileDataProvider = new FromArrayProvider { Data = data }\n};\n</code></pre> <p>Or you can request a file to not be placed in any SOLID block by doing the following:  </p> <pre><code>packerFile.CompressionPreference = CompressionPreference.ZStandard;\npackerFile.SolidType = SolidPreference.NoSolid;\n</code></pre>"},{"location":"Usage/#unpacking_1","title":"Unpacking","text":"<p>This API is not thread safe. If you need to unpack multiple archives in parallel, create a new instance of <code>NxUnpacker</code> for each concurrent operation.</p> <pre><code>var provider = new FromStreamProvider(fileStream);\nvar unpacker = new NxUnpacker(provider);\n// var onDisk = unpacker.ExtractFilesToDisk(unpacker.GetFileEntriesRaw(), temporaryFilePath.FolderPath, new UnpackerSettings());\n// var inMemory = unpacker.ExtractFilesInMemory(unpacker.GetFileEntriesRaw(), new UnpackerSettings());\n</code></pre> <p>To unpack, use the <code>NxUnpacker</code> API. The <code>NxUnpacker</code> constructor takes a <code>IFileDataProvider</code> as a parameter; i.e. the same interface as used by files to be packed. </p>"},{"location":"Usage/#fetching-files","title":"Fetching Files","text":"<p>After using the constructor you can call <code>unpacker.GetFileEntriesRaw()</code> to get a list of file entries from within the archive and use <code>GetFilePath(FileEntry entry);</code> to get the names of the returned entries, i.e.</p> <pre><code>Span&lt;FileEntry&gt; entries = unpacker.GetFileEntriesRaw();\nforeach (var entry in entries) {\nvar name = unpacker.GetFilePath(entry);\n\n// Do something with entry.\n}\n</code></pre>"},{"location":"Usage/#extracting-to-arbitrary-outputs","title":"Extracting to Arbitrary Outputs","text":"<p>If you are extracting the files to disk or memory, you can use <code>unpacker.ExtractFilesToDisk</code>/<code>unpacker.ExtractFilesInMemory</code> directly instead.</p> <p>This example shows how to manually set up extracting to an array.</p> <pre><code>Span&lt;FileEntry&gt; files = unpacker.GetFileEntriesRaw();\n// outputs must be covariant with IOutputDataProvider[]\nvar outputs = new OutputArrayProvider[files.Length];\nfor (var x = 0; x &lt; files.Length; x++)\n{\nvar entry = files[x];\nvar relPath = unpacker.GetFilePath(entry);\noutputs.DangerousGetReferenceAt(x) = new OutputArrayProvider(relPath, entry);\n}\n\n// Extract the files.\nunpacker.ExtractFiles(outputs, new UnpackerSettings());\n\n// Results are available in `outputs` array.\n</code></pre> <p>To unpack to an arbitrary source, prepare an array of <code>IOutputDataProvider</code> and call <code>unpacker.ExtractFiles</code>.  </p> <p>You can find existing implementations of <code>IOutputDataProvider</code> in the <code>NexusMods.Archives.Nx.FileProviders</code> namespace,  they follow the naming convention <code>OutputXXXProvider</code>.</p> <p>Warning</p> <p>Implementations of <code>IOutputDataProvider</code> are disposed by the unpacker after use. Do not manually dispose or use <code>using</code>  statement; they will be disposed as needed.</p>"},{"location":"Usage/#low-level-api","title":"Low Level API","text":"<p>Low level APIs, such as those for creating blocks for packing and chunking files are currently not exposed.</p>"},{"location":"Library/About/","title":"About","text":"<p>Info</p> <p>This section of the documentation covers the remaining public API of the library which is not mentioned in any of the other sections.</p>"},{"location":"Library/About/#disclaimer","title":"Disclaimer","text":"<p>Note</p> <p>Most of the content in the below pages was generated by a large language model (LLM) based on the source code;  then manually verified for accuracy. If there are any missed inaccuracies, please raise an issue.</p>"},{"location":"Library/FileProviders/About/","title":"File Providers","text":"<p>In this project <code>File Providers</code> are types that satisfy the <code>IFileDataProvider</code> or <code>IOutputDataProvider</code> interfaces.</p> <p>These interfaces declare the <code>IFileData GetFileData(long start, uint length)</code> method. The <code>IFileData</code> interface is defined as:  </p> <pre><code>/// &lt;summary&gt;\n///     An interface for providing access to underlying file data.\n/// &lt;/summary&gt;\n/// &lt;remarks&gt;\n///     For read operations where entire file is not yet available e.g. over a network; you should stall until you can\n///     provide enough data to provide.\n/// &lt;/remarks&gt;\npublic unsafe interface IFileData : IDisposable\n{\n/// &lt;summary&gt;\n///     Data of the underlying item.\n/// &lt;/summary&gt;\npublic byte* Data { get; }\n\n/// &lt;summary&gt;\n///     Length of the underlying data.\n/// &lt;/summary&gt;\npublic nuint DataLength { get; }\n}\n</code></pre> <p>And represents a chunk of data from a file. This can be a chunk of a file to be written, or a chunk of a file to be read. Sources of <code>IFileData</code> can vary, for example, it can be a <code>Memory Mapped File</code> on disk, data received from the web or simply an array in memory.</p> <p>The <code>.nx</code> Packer and Unpacker will call the method <code>GetFileData(long start, uint length)</code> to get a slice of the data which it can directly read or write to.</p>"},{"location":"Library/FileProviders/About/#example","title":"Example","text":"<p>Actual Example from Source Code</p> <pre><code>/// &lt;summary&gt;\n///     File data provider that provides info from an array.\n/// &lt;/summary&gt;\npublic sealed class FromArrayProvider : IFileDataProvider\n{\n/// &lt;summary&gt;\n///     The array held by this provider.\n/// &lt;/summary&gt;\npublic required byte[] Data { get; init; }\n\n/// &lt;inheritdoc /&gt;\npublic IFileData GetFileData(long start, uint length) =&gt; new ArrayFileData(Data, start, length);\n}\n\n/// &lt;summary&gt;\n///     Implementation of &lt;see cref=\"IFileData\" /&gt; backed up by a pinned array.\n/// &lt;/summary&gt;\npublic sealed unsafe class ArrayFileData : IFileData\n{\n/// &lt;inheritdoc /&gt;\npublic byte* Data { get; }\n\n/// &lt;inheritdoc /&gt;\npublic nuint DataLength { get; }\n\nprivate GCHandle _handle;\nprivate bool _disposed;\n\n/// &lt;summary&gt;\n///     Creates file data backed by an array.\n/// &lt;/summary&gt;\n/// &lt;param name=\"data\"&gt;The data backed up by the array.&lt;/param&gt;\n/// &lt;param name=\"start\"&gt;Start offset.&lt;/param&gt;\n/// &lt;param name=\"length\"&gt;Length into the data.&lt;/param&gt;\npublic ArrayFileData(byte[] data, long start, uint length)\n{\n_handle = GCHandle.Alloc(data, GCHandleType.Pinned);\nData = (byte*)_handle.AddrOfPinnedObject() + start;\n// ReSharper disable once RedundantCast\nDataLength = (nuint)length;\n}\n\n/// &lt;inheritdoc /&gt;\n~ArrayFileData() =&gt; Dispose();\n\n/// &lt;inheritdoc /&gt;\npublic void Dispose()\n{\nif (_disposed)\nreturn;\n\n_disposed = true;\n_handle.Free();\nGC.SuppressFinalize(this);\n}\n}\n</code></pre>"},{"location":"Library/FileProviders/Interfaces/","title":"Interfaces","text":"<p>These interfaces define the structure for providing access to underlying file data and creating instances of file data,  particularly useful for unpacking purposes.</p>"},{"location":"Library/FileProviders/Interfaces/#ifiledata-interface","title":"IFileData Interface","text":"<p>!!! info \"The <code>IFileData</code> interface provides access to underlying file data. This is particularly useful for read  operations where the entire file is not yet available, such as over a network; you should stall until you can provide enough data.\"</p>"},{"location":"Library/FileProviders/Interfaces/#properties","title":"Properties","text":"<ul> <li><code>Data</code>: A pointer to the data of the underlying item.</li> <li><code>DataLength</code>: The length of the underlying data.</li> </ul>"},{"location":"Library/FileProviders/Interfaces/#ifiledataprovider-interface","title":"IFileDataProvider Interface","text":"<p>The <code>IFileDataProvider</code> interface creates <code>IFileData</code> instances for the purposes of getting data for the archiving operation.</p>"},{"location":"Library/FileProviders/Interfaces/#methods","title":"Methods","text":"<ul> <li><code>GetFileData(long start, uint length)</code>: Gets the file data behind this provider.</li> </ul>"},{"location":"Library/FileProviders/Interfaces/#ioutputdataprovider-interface","title":"IOutputDataProvider Interface","text":"<p>The <code>IOutputDataProvider</code> interface creates <code>IFileData</code> instances which allow the user to output information for unpacking purposes. Note that items are disposed upon successful write to target, not explicitly by the user.</p>"},{"location":"Library/FileProviders/Interfaces/#properties_1","title":"Properties","text":"<ul> <li><code>RelativePath</code>: The relative path to the output location.</li> <li><code>Entry</code>: The entry this provider is for.</li> </ul>"},{"location":"Library/FileProviders/Interfaces/#methods_1","title":"Methods","text":"<ul> <li><code>GetFileData(long start, uint length)</code>: Gets the output data behind this provider. Returns an individual <code>IFileData</code> buffer to write decompressed data to. Make sure to dispose, for example with a 'using' statement.</li> </ul>"},{"location":"Library/FileProviders/FileData/ArrayFileData/","title":"ArrayFileData","text":"<p>The <code>ArrayFileData</code> class is an implementation of <code>IFileData</code> backed up by a pinned array.</p>"},{"location":"Library/FileProviders/FileData/ArrayFileData/#properties","title":"Properties","text":"<ul> <li><code>Data</code>: The pointer to the start of the data.</li> <li><code>DataLength</code>: The length of the data.</li> </ul>"},{"location":"Library/FileProviders/FileData/ArrayFileData/#constructors","title":"Constructors","text":"<ul> <li><code>ArrayFileData(byte[] data, long start, uint length)</code>: Creates file data backed by an array.</li> </ul>"},{"location":"Library/FileProviders/FileData/ArrayFileData/#destructor","title":"Destructor","text":"<ul> <li><code>~ArrayFileData()</code>: Disposes the object, freeing the pinned handle.</li> </ul>"},{"location":"Library/FileProviders/FileData/ArrayFileData/#methods","title":"Methods","text":"<ul> <li><code>Dispose()</code>: Frees the pinned handle.</li> </ul>"},{"location":"Library/FileProviders/FileData/MemoryMappedFileData/","title":"MemoryMappedFileData","text":"<p>The <code>MemoryMappedFileData</code> class is an implementation of <code>IFileData</code> backed up by memory-mapped files. It provides an efficient way to work with large data files.</p>"},{"location":"Library/FileProviders/FileData/MemoryMappedFileData/#properties","title":"Properties","text":"<ul> <li><code>Data</code>: The pointer to the start of the data.</li> <li><code>DataLength</code>: The length of the data.</li> </ul>"},{"location":"Library/FileProviders/FileData/MemoryMappedFileData/#constructors","title":"Constructors","text":"<ul> <li><code>MemoryMappedFileData(string filePath, long start, uint length)</code>: Creates file data backed by a memory mapped file from a given file path.</li> <li><code>MemoryMappedFileData(FileStream stream, long start, uint length)</code>: Creates file data backed by a memory mapped file from a given file stream.</li> </ul>"},{"location":"Library/FileProviders/FileData/MemoryMappedFileData/#destructor","title":"Destructor","text":"<ul> <li><code>~MemoryMappedFileData()</code>: Disposes the object, freeing the memory-mapped file and its view.</li> </ul>"},{"location":"Library/FileProviders/FileData/MemoryMappedFileData/#methods","title":"Methods","text":"<ul> <li><code>Dispose()</code>: Frees the memory-mapped file and its view.</li> </ul>"},{"location":"Library/FileProviders/FileData/MemoryMappedFileData/#usage","title":"Usage","text":"<p>This class provides an efficient way to handle large data files. It uses memory-mapped files to access parts of a file  as if they were in memory. Here's a brief example:</p> <pre><code>using var fileData = new MemoryMappedFileData(\"path/to/file\", 0, 100);\n\n// Do something with fileData...\n</code></pre> <p>In this example, the <code>MemoryMappedFileData</code> maps the first 100 bytes of the file at the given path into memory.  The resulting <code>MemoryMappedFileData</code> object provides a pointer to the start of the data and the length of the data.</p>"},{"location":"Library/FileProviders/FileData/RentedArrayFileData/","title":"RentedArrayFileData","text":"<p>The <code>RentedArrayFileData</code> class is an implementation of <code>IFileData</code> backed up by an <code>ArrayPool</code> rental.</p>"},{"location":"Library/FileProviders/FileData/RentedArrayFileData/#properties","title":"Properties","text":"<ul> <li><code>Data</code>: The pointer to the start of the data.</li> <li><code>DataLength</code>: The length of the data.</li> </ul>"},{"location":"Library/FileProviders/FileData/RentedArrayFileData/#constructors","title":"Constructors","text":"<ul> <li><code>RentedArrayFileData(ArrayRentalSlice data)</code>: Creates file data backed by a rented array.</li> </ul>"},{"location":"Library/FileProviders/FileData/RentedArrayFileData/#destructor","title":"Destructor","text":"<ul> <li><code>~RentedArrayFileData()</code>: Disposes the object, freeing the pinned array.</li> </ul>"},{"location":"Library/FileProviders/FileData/RentedArrayFileData/#methods","title":"Methods","text":"<ul> <li><code>Dispose()</code>: Frees the pinned array.</li> </ul>"},{"location":"Library/FileProviders/FileData/RentedArrayFileData/#usage","title":"Usage","text":"<pre><code>var slice = new ArrayRentalSlice(new ArrayRental&lt;byte&gt;(666), 666);\nusing var fileData = new RentedArrayFileData(slice);\n\n// Do something with fileData...\n</code></pre> <p>In this example, the <code>RentedArrayFileData</code> wraps a slice of a rented array. The resulting <code>RentedArrayFileData</code> object  provides a pointer to the start of the data and the length of the data.</p>"},{"location":"Library/FileProviders/Inputs/FromArrayProvider/","title":"FromArrayProvider","text":"<p>These classes are part of a system that provides and manages data from an array for files.</p>"},{"location":"Library/FileProviders/Inputs/FromArrayProvider/#fromarrayprovider_1","title":"FromArrayProvider","text":"<p>The <code>FromArrayProvider</code> class is a file data provider that provides info from an array.</p>"},{"location":"Library/FileProviders/Inputs/FromArrayProvider/#properties","title":"Properties","text":"<ul> <li><code>Data</code>: The array held by this provider.</li> </ul>"},{"location":"Library/FileProviders/Inputs/FromArrayProvider/#methods","title":"Methods","text":"<ul> <li><code>GetFileData(long start, uint length)</code>: Returns file data backed by the array it holds.</li> </ul>"},{"location":"Library/FileProviders/Inputs/FromArrayProvider/#usage","title":"Usage","text":"<p>These classes work together to provide and manage file data from an array. Here's a brief example:</p> <pre><code>var provider = new FromArrayProvider\n{\nData = new byte[] { 1, 2, 3, 4, 5 }\n};\n\nusing var fileData = provider.GetFileData(1, 2);\n\n// Do something with fileData...\n</code></pre>"},{"location":"Library/FileProviders/Inputs/FromDirectoryDataProvider/","title":"FromDirectoryDataProvider","text":"<p>The <code>FromDirectoryDataProvider</code> provides file data from a file in a given directory.</p>"},{"location":"Library/FileProviders/Inputs/FromDirectoryDataProvider/#properties","title":"Properties","text":"<ul> <li><code>Directory</code>: The directory from which the data will be fetched.</li> <li><code>RelativePath</code>: Relative path to the directory.</li> </ul>"},{"location":"Library/FileProviders/Inputs/FromDirectoryDataProvider/#methods","title":"Methods","text":""},{"location":"Library/FileProviders/Inputs/FromDirectoryDataProvider/#getfiledata","title":"GetFileData","text":"<p>Retrieves file data from the directory based on the given start index and length.</p> <pre><code>public IFileData GetFileData(long start, uint length)\n</code></pre>"},{"location":"Library/FileProviders/Inputs/FromDirectoryDataProvider/#usage","title":"Usage","text":"<p>The <code>FromDirectoryDataProvider</code> is used to fetch file data from a directory. The directory and relative path are stored separately to save memory. When <code>GetFileData</code> is called, the directory and relative path are combined temporarily to fetch the data. Here's an example:</p> <pre><code>var dataProvider = new FromDirectoryDataProvider\n{\nDirectory = \"/path/to/directory\",\nRelativePath = \"relative/path/to/file\"\n};\n\nusing var fileData = dataProvider.GetFileData(0, 1024);\n\n// Use fileData...\n</code></pre> <p>In this example, a <code>FromDirectoryDataProvider</code> is created and used to fetch the first 1024 bytes of a file located in  the directory <code>/path/to/directory</code> and the relative path <code>relative/path/to/file</code>. The resulting <code>IFileData</code> object  can then be used as needed.</p>"},{"location":"Library/FileProviders/Inputs/FromStreamProvider/","title":"FromStreamProvider","text":"<p>The <code>FromStreamProvider</code> class is a file data provider that provides file data from a stream.</p> <p>Underlying stream must support seeking.</p>"},{"location":"Library/FileProviders/Inputs/FromStreamProvider/#properties","title":"Properties","text":"<ul> <li><code>Stream</code>: The stream associated with this provider.</li> <li><code>StreamStart</code>: The start position of the stream.</li> </ul>"},{"location":"Library/FileProviders/Inputs/FromStreamProvider/#constructors","title":"Constructors","text":"<ul> <li><code>FromStreamProvider(stream)</code>: Creates a <code>FromStreamProvider</code> instance with the specified stream.</li> </ul>"},{"location":"Library/FileProviders/Inputs/FromStreamProvider/#methods","title":"Methods","text":""},{"location":"Library/FileProviders/Inputs/FromStreamProvider/#getfiledata","title":"GetFileData","text":"<p>Retrieves file data from the stream based on the given start index and length.</p> <pre><code>public IFileData GetFileData(long start, uint length)\n</code></pre>"},{"location":"Library/FileProviders/Inputs/FromStreamProvider/#usage","title":"Usage","text":"<pre><code>var provider = new FromStreamProvider(GetFileStream());\n\n// Get file data from the stream\nusing var fileData = provider.GetFileData(0, 1024);\n\n// Use fileData...\n</code></pre> <p>In this example, a stream is obtained from a source, and a <code>FromStreamProvider</code> is created with the stream.  The <code>GetFileData</code> method is then used to retrieve file data from the stream starting at index 0 with a length of 1024.  The resulting <code>IFileData</code> object can be used as needed.</p>"},{"location":"Library/FileProviders/Outputs/OutputArrayProvider/","title":"OutputArrayProvider Class","text":"<p>The <code>OutputArrayProvider</code> is an output data provider that writes data to an array. It is used for extracting archived content to a byte array.</p>"},{"location":"Library/FileProviders/Outputs/OutputArrayProvider/#properties","title":"Properties","text":"<ul> <li><code>Data</code>: The byte array held by this provider.</li> <li><code>RelativePath</code>: The relative path of the file.</li> <li><code>Entry</code>: The file entry from the archive.</li> </ul>"},{"location":"Library/FileProviders/Outputs/OutputArrayProvider/#constructors","title":"Constructors","text":"<ul> <li><code>OutputArrayProvider(string relativePath, FileEntry entry)</code>: Initializes an <code>OutputArrayProvider</code> with the specified relative path and file entry.</li> </ul>"},{"location":"Library/FileProviders/Outputs/OutputArrayProvider/#methods","title":"Methods","text":""},{"location":"Library/FileProviders/Outputs/OutputArrayProvider/#getfiledata","title":"GetFileData","text":"<p>Retrieves the file data from the array based on the given start index and length.</p> <pre><code>public IFileData GetFileData(long start, uint length)\n</code></pre>"},{"location":"Library/FileProviders/Outputs/OutputArrayProvider/#dispose","title":"Dispose","text":"<p>Disposes of the output array provider and releases any resources associated with it.</p> <pre><code>public void Dispose()\n</code></pre>"},{"location":"Library/FileProviders/Outputs/OutputArrayProvider/#examples","title":"Examples","text":"<pre><code>// Assuming unpacker is an instance of NxUnpacker and files is a collection of FileEntry instances from NxUnpacker\nvar entry = files[x];\nvar relPath = unpacker.GetFilePath(entry.FilePathIndex);\nvar provider = new OutputArrayProvider(relPath, entry);\n</code></pre>"},{"location":"Library/FileProviders/Outputs/OutputFileProvider/","title":"OutputFileProvider Class","text":"<p>The <code>OutputFileProvider</code> is an output data provider that writes data to a file. It is used for extracting archived content to a file on disk.</p>"},{"location":"Library/FileProviders/Outputs/OutputFileProvider/#properties","title":"Properties","text":"<ul> <li><code>RelativePath</code>: The relative path of the file.</li> <li><code>Entry</code>: The file entry from the archive.</li> </ul>"},{"location":"Library/FileProviders/Outputs/OutputFileProvider/#constructors","title":"Constructors","text":"<ul> <li><code>OutputFileProvider(string outputFolder, string relativePath, FileEntry entry)</code>: Initializes an <code>OutputFileProvider</code> with the specified output folder, relative path, and file entry.</li> </ul>"},{"location":"Library/FileProviders/Outputs/OutputFileProvider/#methods","title":"Methods","text":""},{"location":"Library/FileProviders/Outputs/OutputFileProvider/#getfiledata","title":"GetFileData","text":"<p>Retrieves the file data from the array based on the given start index and length.</p> <pre><code>public IFileData GetFileData(long start, uint length)\n</code></pre>"},{"location":"Library/FileProviders/Outputs/OutputFileProvider/#dispose","title":"Dispose","text":"<p>Disposes of the output file provider and releases any resources associated with it.</p> <pre><code>public void Dispose()\n</code></pre>"},{"location":"Library/FileProviders/Outputs/OutputFileProvider/#usage","title":"Usage","text":"<p>The <code>OutputFileProvider</code> class is used to output extracted file data to a file. Here's an example of how to use it:</p> <pre><code>// Assuming unpacker is an instance of NxUnpacker and files is a collection of FileEntry instances from NxUnpacker\nvar entry = files[x];\nstring outputFolder = \"C:\\\\OutputFolder\";\nstring relativePath = \"folder\\\\file.txt\";\nvar provider = new OutputFileProvider(outputFolder, relativePath, entry);\n</code></pre>"},{"location":"Library/Headers/About/","title":"About Headers","text":"<p>This section of the documentation details the APIs available for parsing the file metadata.</p>"},{"location":"Library/Headers/HeaderParser/","title":"HeaderParser Class","text":"<p>The <code>HeaderParser</code> class is a utility for parsing <code>.nx</code> file header.</p> <p>You can use this to parse just the header (incl. Table of Contents) if you don't want to extract the files.</p>"},{"location":"Library/Headers/HeaderParser/#methods","title":"Methods","text":""},{"location":"Library/Headers/HeaderParser/#parseheader","title":"ParseHeader","text":"<p>Parses the header from a given data provider.</p> <p>This is a wrapper around TryParseHeader that does automatic error handling and extracts the full header.</p> <p>The difference between this and TryParseHeader is that in more exotic settings like downloading header over a network, TryParseHeader will return immediately on insufficient data, while <code>ParseHeader</code>  might stall until all data is available.</p> <pre><code>static unsafe ParsedHeader ParseHeader(IFileDataProvider provider, bool hasLotsOfFiles = false)\n</code></pre>"},{"location":"Library/Headers/HeaderParser/#parameters","title":"Parameters","text":"<ul> <li><code>provider</code>: Provides the header data.</li> <li><code>hasLotsOfFiles</code>: This is a hint to the parser whether the file to be parsed contains lots of individual files (100+).</li> </ul>"},{"location":"Library/Headers/HeaderParser/#returns","title":"Returns","text":"<p>A successfully parsed <code>ParsedHeader</code> instance.</p>"},{"location":"Library/Headers/HeaderParser/#exceptions","title":"Exceptions","text":"<ul> <li><code>NotANexusArchiveException</code>: Not a Nexus Archive.</li> </ul>"},{"location":"Library/Headers/HeaderParser/#tryparseheader","title":"TryParseHeader","text":"<p>Tries to read the header from the given data.</p> <pre><code>public static unsafe HeaderParserResult TryParseHeader(byte* data, int dataSize)\n</code></pre>"},{"location":"Library/Headers/HeaderParser/#parameters_1","title":"Parameters","text":"<ul> <li><code>data</code>: Pointer to header data.</li> <li><code>dataSize</code>: Number of bytes available at <code>data</code>.</li> </ul>"},{"location":"Library/Headers/HeaderParser/#returns_1","title":"Returns","text":"<p>A result with <code>HeaderParserResult.Header</code> not null if parsed, else <code>HeaderParserResult.Header</code> is null and you should  call this method again with a larger <code>dataSize</code>. The required number of bytes is specified in <code>HeaderParserResult.HeaderSize</code>.</p>"},{"location":"Library/Headers/HeaderParser/#exceptions_1","title":"Exceptions","text":"<ul> <li><code>NotANexusArchiveException</code>: Not a Nexus Archive.</li> </ul>"},{"location":"Library/Headers/HeaderParser/#headerparserresult-struct","title":"HeaderParserResult Struct","text":"<p>Stores the result of parsing header.</p>"},{"location":"Library/Headers/HeaderParser/#properties","title":"Properties","text":"<ul> <li><code>Header</code>: The parsed header to use with extraction logic. If this header is null, insufficient bytes are available and you should get required header size from <code>HeaderSize</code> and call the method again once you have enough bytes.</li> <li><code>HeaderSize</code>: Required size of the header + toc in bytes.</li> </ul>"},{"location":"Library/Headers/HeaderParser/#constructors","title":"Constructors","text":"<ul> <li><code>HeaderParserResult()</code>: Creates a <code>HeaderParserResult</code>.</li> </ul>"},{"location":"Library/Headers/HeaderParser/#examples","title":"Examples","text":""},{"location":"Library/Headers/HeaderParser/#parsing-a-header","title":"Parsing a Header","text":"<pre><code>var provider = new FromArrayProvider() { Data = data };\nvar parsedHeader = HeaderParser.ParseHeader(provider);\n</code></pre>"},{"location":"Library/Headers/HeaderParser/#trying-to-parse-a-header","title":"Trying to Parse a Header","text":"<pre><code>var provider = new SomeNetworkProvider(someUrl);\nusing var data = provider.GetFileData(0, (uint)headerSize);\nvar result = TryParseHeader(data.Data, headerSize);\nif (result.Header != null)\nConsole.WriteLine(\"Header parsed successfully!\");\nelse\nConsole.WriteLine(\"Failed to parse header. Required header size: \" + result.HeaderSize);\n</code></pre>"},{"location":"Library/Headers/StringPool/","title":"StringPool","text":"<p>The structure and purpose of the StringPool is detailed in the specification.</p>"},{"location":"Library/Headers/StringPool/#constants","title":"Constants","text":"<ul> <li><code>MaxCompressedSize</code>: The maximum allowed size of the compressed string pool.</li> <li><code>DefaultCompressionLevel</code>: The default compression level used for the <code>Zstandard</code> compression algorithm.</li> </ul>"},{"location":"Library/Headers/StringPool/#methods","title":"Methods","text":""},{"location":"Library/Headers/StringPool/#pack","title":"Pack","text":"<p>This method packs a list of items into the string pool.</p> <pre><code>public static unsafe ArrayRentalSlice Pack&lt;T&gt;(Span&lt;T&gt; items) where T : IHasRelativePath\n</code></pre> <p>This method takes a <code>Span&lt;T&gt;</code> of items, where <code>T</code> is a type implementing the <code>IHasRelativePath</code> interface. The items are sorted lexicographically and packed into the string pool.</p> <p>This sorts the span directly, i.e. order of items in the span will be different after calling the method.</p>"},{"location":"Library/Headers/StringPool/#unpack","title":"Unpack","text":"<p>These methods decompress a previously packed string pool, returning an array of the original strings.</p> <pre><code>public static unsafe string[] Unpack(byte* poolPtr, int compressedDataSize)\npublic static unsafe string[] Unpack(byte* poolPtr, int compressedDataSize, int fileCountHint)\npublic static unsafe string[] Unpack(Span&lt;byte&gt; poolSpan)\npublic static unsafe string[] Unpack(Span&lt;byte&gt; poolSpan, int fileCountHint)\n</code></pre> <p>These methods take a pointer to the compressed string pool and the size of the compressed data. They return an array of the original strings. Optionally, you can provide a hint for the number of files contained in the string pool.</p>"},{"location":"Library/Headers/StringPool/#examples","title":"Examples","text":""},{"location":"Library/Headers/StringPool/#packing-strings-into-the-string-pool","title":"Packing Strings into the String Pool","text":"<pre><code>// Create a list of items implementing IHasRelativePath interface.\nSpan&lt;IHasRelativePath&gt; items = new IHasRelativePath[]\n{\nnew Item { RelativePath = \"item1\" },\nnew Item { RelativePath = \"item2\" },\n// ...\n};\n\n// Pack the items into the string pool.\nusing var packedData = StringPool.Pack(items);\n</code></pre>"},{"location":"Library/Headers/StringPool/#unpacking-strings-from-the-string-pool","title":"Unpacking Strings from the String Pool","text":"<pre><code>// Assume we have a byte pointer to the compressed string pool and its size.\nbyte* poolPtr = ...;\nint compressedDataSize = ...;\n\n// Unpack the strings from the string pool.\nvar strings = StringPool.Unpack(poolPtr, compressedDataSize);\n\n// Now, 'strings' contains the original strings.\n</code></pre>"},{"location":"Library/Traits/About/","title":"Traits","text":"<p>In this project <code>Traits</code> are defined as interfaces where we use them in the following manner</p> <pre><code>public byte[] Method&lt;T&gt;(T item) where T : ITrait\n{\nreturn default;\n}\n</code></pre> <p>The idea is to use the <code>where</code> constraint for generic parameters. This will cause the method to be JIT'ted with the concrete type, and therefore eliminate virtual call overhead.</p>"},{"location":"Library/Traits/ICanConvertToLittleEndian/","title":"ICanConvertToLittleEndian","text":"<p>The <code>ICanConvertToLittleEndian</code> trait is for structures that can convert to Little Endian format.</p> <p>It provides the <code>ReverseEndianIfNeeded</code> method for reversing the endian of the data on a big endian machine, if required.</p>"},{"location":"Library/Traits/ICanConvertToLittleEndian/#methods","title":"Methods","text":""},{"location":"Library/Traits/ICanConvertToLittleEndian/#reverseendianifneeded","title":"ReverseEndianIfNeeded","text":"<pre><code>public void ReverseEndianIfNeeded();\n</code></pre> <p>Reverses the endian of the data if needed. Only call this method once, or endian will be reversed again. This is intended to be used in cases where you receive a structure from an external source, e.g. reading an .nx file from disk or transferred over the network.</p> <p>The implementing methods of this interface are defined as follows</p> <pre><code>if (BitConverter.IsLittleEndian)\nreturn;\n\nReverseEndian(); </code></pre> <p>The <code>BitConverter.IsLittleEndian</code> is evaluated at compile-time (JIT-time) and is a no-op on Little Endian machines.</p>"},{"location":"Library/Traits/ICanConvertToLittleEndian/#usage","title":"Usage","text":"<pre><code>public struct MyStruct : ICanConvertToLittleEndian\n{\npublic int MyValue;\n\npublic void ReverseEndianIfNeeded()\n{\nif (BitConverter.IsLittleEndian)\nreturn;\n\nMyValue = BinaryPrimitives.ReverseEndianness(MyValue);\n}\n}\n</code></pre> <p>In the above example, <code>MyStruct</code> implements the <code>ICanConvertToLittleEndian</code> interface. The <code>ReverseEndianIfNeeded</code> method checks if the system is Little Endian. If not, it reverses the endian of <code>MyValue</code>.  </p>"},{"location":"Library/Traits/ICanProvideFileData/","title":"ICanProvideFileData","text":"<p><code>ICanProvideFileData</code> is a trait for items which can provide data to be compressed</p> <p>This trait is used inside the packing code (notably in <code>PackerFile</code>) to provide the bytes to be compressed.</p>"},{"location":"Library/Traits/ICanProvideFileData/#properties","title":"Properties","text":""},{"location":"Library/Traits/ICanProvideFileData/#filedataprovider","title":"FileDataProvider","text":"<pre><code>IFileDataProvider FileDataProvider { get; }\n</code></pre>"},{"location":"Library/Traits/ICanProvideFileData/#usage","title":"Usage","text":"<pre><code>public class MyFileDataClass : ICanProvideFileData\n{\n/// &lt;inheritdoc /&gt;\npublic required IFileDataProvider FileDataProvider { get; init; }\n}\n\n// Get the data.\nusing var data = MyFileDataClass.FileDataProvider.GetFileData(StartOffset, (uint)ChunkSize);\n</code></pre> <p>In this example, <code>MyFileDataClass</code> implements the <code>ICanProvideFileData</code> interface. <code>MyFileDataClass</code> can then be used in methods constrained with <code>where T : ICanProvideFileData</code>.</p>"},{"location":"Library/Traits/IHasCompressionPreference/","title":"IHasCompressionPreference","text":"<p>The <code>IHasCompressionPreference</code> trait allows an item to declare the compression algorithm it wants to be processed with.</p>"},{"location":"Library/Traits/IHasCompressionPreference/#properties","title":"Properties","text":""},{"location":"Library/Traits/IHasCompressionPreference/#compressionpreference","title":"CompressionPreference","text":"<pre><code>CompressionPreference CompressionPreference { get; }\n</code></pre> <p>This property gets the preferred algorithm to compress the item with. The <code>CompressionPreference</code> enum specifies the available compression algorithms.</p> <p>The <code>CompressionPreference</code> enum defines the following values (at time of writing):  </p> <ul> <li><code>NoPreference</code>: No preference is specified.  </li> <li><code>Copy</code>: Do not compress at all, copy data verbatim.  </li> <li><code>ZStandard</code>: Compress with ZStandard.  </li> <li><code>Lz4</code>: Compress with LZ4.  </li> </ul>"},{"location":"Library/Traits/IHasCompressionPreference/#usage","title":"Usage","text":"<pre><code>public class MyCompressibleItem : IHasCompressionPreference\n{\n/// &lt;inheritdoc /&gt;\npublic required CompressionPreference CompressionPreference { get; init; }\n}\n\n// Set the preference.\nMyCompressibleItem.CompressionPreference = CompressionPreference.Lz4;\n</code></pre> <p>In this example, <code>MyCompressibleItem</code> implements the <code>IHasCompressionPreference</code> interface. <code>MyCompressibleItem</code> can then be used in methods constrained with <code>where T : IHasCompressionPreference</code>.</p>"},{"location":"Library/Traits/IHasFileSize/","title":"IHasFileSize","text":"<p>The <code>IHasFileSize</code> trait allows items to specify a file size in bytes.</p>"},{"location":"Library/Traits/IHasFileSize/#properties","title":"Properties","text":""},{"location":"Library/Traits/IHasFileSize/#filesize","title":"FileSize","text":"<pre><code>long FileSize { get; }\n</code></pre> <p>This property gets the size of the item in bytes.</p>"},{"location":"Library/Traits/IHasFileSize/#usage","title":"Usage","text":"<p>The <code>IHasFileSize</code> interface is used to indicate that an item can specify its file size. Implementing this interface in a class allows the class to expose the <code>FileSize</code> property.</p> <pre><code>public class MyFileSizeItem : IHasFileSize\n{\n/// &lt;inheritdoc /&gt;\npublic required long FileSize { get; init; }\n}\n</code></pre> <p>In this example, <code>MyFileSizeItem</code> implements the <code>IHasFileSize</code> interface. <code>MyFileSizeItem</code> can then be used in methods constrained with <code>where T : IHasFileSize</code>.</p>"},{"location":"Library/Traits/IHasRelativePath/","title":"IHasRelativePath","text":"<p>The <code>IHasRelativePath</code> trait allows items to specify a relative path to the file from the archive or folder root.</p>"},{"location":"Library/Traits/IHasRelativePath/#properties","title":"Properties","text":""},{"location":"Library/Traits/IHasRelativePath/#relativepath","title":"RelativePath","text":"<pre><code>string RelativePath { get; }\n</code></pre> <p>This property gets the relative path to the file from the archive or folder root.</p>"},{"location":"Library/Traits/IHasRelativePath/#usage","title":"Usage","text":"<p>The <code>IHasRelativePath</code> interface is used to indicate that an item contains a file path.  Implementing this interface in a class allows the class to expose the <code>RelativePath</code> property.</p> <pre><code>public class MyFileItem : IHasRelativePath\n{\n/// &lt;inheritdoc /&gt;\npublic string RelativePath { get; set; }\n}\n</code></pre> <p>In this example, <code>MyFileItem</code> implements the <code>IHasRelativePath</code> interface. <code>MyFileItem</code> can then be used in methods constrained with <code>where T : IHasRelativePath</code>.</p>"},{"location":"Library/Traits/IHasSolidType/","title":"IHasSolidType","text":"<p>The <code>IHasSolidType</code> trait is used for items that can specify a preference on whether they'd prefer to be SOLIDly packed or not.</p>"},{"location":"Library/Traits/IHasSolidType/#properties","title":"Properties","text":""},{"location":"Library/Traits/IHasSolidType/#solidtype","title":"SolidType","text":"<pre><code>SolidPreference SolidType { get; }\n</code></pre> <p>This property gets the preference in terms of whether the item should be SOLID (packed in a solid block) or not. The <code>SolidPreference</code> enum specifies the available preferences.</p> <p>The <code>SolidPreference</code> enum defines the following values (at time of writing):</p> <ul> <li><code>Default</code>: Pack into a solid block if possible.  </li> <li><code>NoSolid</code>: This file must not be packed in a solid block.  </li> </ul>"},{"location":"Library/Traits/IHasSolidType/#usage","title":"Usage","text":"<pre><code>public class MyPackedItem : IHasSolidType\n{\npublic SolidPreference SolidType { get; set; }\n}\n\n// Set the preference.\nMyPackedItem.SolidType = SolidPreference.Default;\n</code></pre> <p>In this example, <code>MyPackedItem</code> implements the <code>IHasSolidType</code> interface. <code>MyPackedItem</code> can then be used in methods constrained with <code>where T : IHasSolidType</code>.</p>"},{"location":"Library/Utilities/ArrayRental/","title":"ArrayRental","text":"<p><code>ArrayRental</code> is a struct that represents an instance of a rented array. It should be disposed of after use with the <code>using</code> statement.</p> <p>The underlying array is managed by the shared <code>ArrayPool</code>.</p>"},{"location":"Library/Utilities/ArrayRental/#properties","title":"Properties","text":"<ul> <li><code>Array</code>: The underlying array for this rental.</li> <li><code>Span</code>: Span for the underlying array. May be larger than requested length.</li> </ul>"},{"location":"Library/Utilities/ArrayRental/#constructor","title":"Constructor","text":"<pre><code>public ArrayRental(int numBytes)\n</code></pre> <p>Rents a requested minimum number of bytes. Amount of data rented might be larger.</p>"},{"location":"Library/Utilities/ArrayRental/#slices","title":"Slices","text":"<p><code>ArrayRentalSlice</code> represents a slice of an <code>ArrayRental</code>. This API is meant to be used as a return value from methods, and transfers ownership of the rental from the internal <code>ArrayRental</code>.</p> <pre><code>public ArrayRentalSlice(ArrayRental rental, int length)\n</code></pre> <p>Represents a slice of the array rental.</p>"},{"location":"Library/Utilities/ArrayRental/#usage","title":"Usage","text":""},{"location":"Library/Utilities/ArrayRental/#rent-an-array-and-create-a-slice","title":"Rent an Array and Create a Slice","text":"<p>Make sure to dispose with <code>using</code> statement or explicit dispose.</p> <pre><code>// Will create a rental of at least 4096 bytes.\nusing var rental = new ArrayRental(4096);\n</code></pre>"},{"location":"Library/Utilities/ArrayRental/#rent-an-array-and-create-a-slice_1","title":"Rent an Array and Create a Slice","text":"<p>When you create an <code>ArrayRentalSlice</code>, the responsibility of disposing the rental is transferred to the slice. Make sure to not double dispose.</p> <pre><code>// Some Method\nArrayRentalSlice CompressData(byte* data, int length) {\nvar rental = new ArrayRental(numBytes);\n// Compress into rental....\n// And return a slice with just the info needed.\nreturn new ArrayRentalSlice(rental, sliceLength);\n}\n\n// Method consumer\nusing var compressed = CompressData(data, length);\n</code></pre>"},{"location":"Library/Utilities/FileFinder/","title":"FileFinder Class","text":"<p>A utility class for creating <code>PackerFile(s)</code> which can be fed into the packing APIs such as <code>NxPacker.Pack</code>.</p>"},{"location":"Library/Utilities/FileFinder/#methods","title":"Methods","text":"<p>This is a static class.</p>"},{"location":"Library/Utilities/FileFinder/#getfiles","title":"GetFiles","text":"<p>Retrieves all packable files from a directory.</p> <pre><code>List&lt;PackerFile&gt; GetFiles(string directoryPath, SearchOption searchOption)\n</code></pre> <p>The search option specifies whether the search operation should include all subdirectories or only the current directory.</p> <p>Note</p> <p>Depending on the .NET version, the implementation of this method varies. For .NET Standard 2.1 or greater, this method is considerably faster with the use of newer APIs.</p>"},{"location":"Library/Utilities/FileFinder/#getfiles-enumerationoptions","title":"GetFiles (EnumerationOptions)","text":"<p>For .NET Standard 2.1 or greater, the following API is available.</p> <pre><code>List&lt;PackerFile&gt; GetFiles(string directoryPath, EnumerationOptions options)\n</code></pre> <p>This API accepts some additional enumeration options to use when searching for files.</p>"},{"location":"Library/Utilities/FileFinder/#examples","title":"Examples","text":""},{"location":"Library/Utilities/FileFinder/#creating-packable-files","title":"Creating Packable Files","text":"<pre><code>var files = FileFinder.GetFiles(\"C:/Mods/SomeCoolMod\", SearchOption.AllDirectories);\nforeach (var file in files)\nConsole.WriteLine($\"Found file: {file.RelativePath}, Size: {file.FileSize}\");\n</code></pre> <p>In this example, the <code>GetFiles</code> method is used to find all files in the specified directory and its subdirectories. The result of this can be printed to console, or sent straight to the mid-level API packer.  </p>"},{"location":"Library/Utilities/LittleEndianReader/","title":"LittleEndianReader","text":"<p>The <code>LittleEndianReader</code> is a utility for reading data from a pointer in Little Endian format.</p>"},{"location":"Library/Utilities/LittleEndianReader/#properties","title":"Properties","text":"<ul> <li><code>Ptr</code>: Current pointer being read from.</li> </ul>"},{"location":"Library/Utilities/LittleEndianReader/#constructors","title":"Constructors","text":"<ul> <li><code>LittleEndianReader(byte* ptr)</code>: Initializes a new instance of the <code>LittleEndianReader</code> struct with the given pointer.</li> </ul>"},{"location":"Library/Utilities/LittleEndianReader/#methods","title":"Methods","text":""},{"location":"Library/Utilities/LittleEndianReader/#readshort","title":"ReadShort","text":"<p>Reads a signed 16-bit integer from the current pointer in Little Endian format and advances the pointer.</p> <pre><code>public short ReadShort()\n</code></pre>"},{"location":"Library/Utilities/LittleEndianReader/#readushort","title":"ReadUShort","text":"<p>Reads an unsigned 16-bit integer from the current pointer in Little Endian format and advances the pointer.</p> <pre><code>public ushort ReadUShort()\n</code></pre>"},{"location":"Library/Utilities/LittleEndianReader/#readuint","title":"ReadUInt","text":"<p>Reads an unsigned 32-bit integer from the current pointer in Little Endian format and advances the pointer.</p> <pre><code>public uint ReadUInt()\n</code></pre>"},{"location":"Library/Utilities/LittleEndianReader/#readint","title":"ReadInt","text":"<p>Reads a signed 32-bit integer from the current pointer in Little Endian format and advances the pointer.</p> <pre><code>public int ReadInt()\n</code></pre>"},{"location":"Library/Utilities/LittleEndianReader/#readshortatoffset","title":"ReadShortAtOffset","text":"<p>Reads a signed 16-bit integer from the specified offset in Little Endian format without advancing the pointer.</p> <pre><code>public short ReadShortAtOffset(int offset)\n</code></pre>"},{"location":"Library/Utilities/LittleEndianReader/#readintatoffset","title":"ReadIntAtOffset","text":"<p>Reads a signed 32-bit integer from the specified offset in Little Endian format without advancing the pointer.</p> <pre><code>public int ReadIntAtOffset(int offset)\n</code></pre>"},{"location":"Library/Utilities/LittleEndianReader/#readlongatoffset","title":"ReadLongAtOffset","text":"<p>Reads a signed 64-bit integer from the specified offset in Little Endian format without advancing the pointer.</p> <pre><code>public long ReadLongAtOffset(int offset)\n</code></pre>"},{"location":"Library/Utilities/LittleEndianReader/#readulongatoffset","title":"ReadUlongAtOffset","text":"<p>Reads an unsigned 64-bit integer from the specified offset in Little Endian format without advancing the pointer.</p> <pre><code>public ulong ReadUlongAtOffset(int offset)\n</code></pre>"},{"location":"Library/Utilities/LittleEndianReader/#seek","title":"Seek","text":"<p>Advances the pointer by a specified number of bytes.</p> <pre><code>public void Seek(int offset)\n</code></pre>"},{"location":"Library/Utilities/LittleEndianReader/#about-the-offset-methods","title":"About the Offset Methods","text":"<p>The <code>LittleEndianReader</code> struct provides several methods that read from a specific offset without advancing the pointer.  These methods include <code>ReadShortAtOffset</code>, <code>ReadIntAtOffset</code>, <code>ReadLongAtOffset</code>, and <code>ReadUlongAtOffset</code>.</p> <p>While these methods do not significantly reduce the instruction count, they offer some minor performance advantages, you can read more about this in LittleEndianWriter's Section</p>"},{"location":"Library/Utilities/LittleEndianReader/#examples","title":"Examples","text":"<p>The following examples demonstrate how to use the <code>LittleEndianReader</code> struct for various tasks:</p>"},{"location":"Library/Utilities/LittleEndianReader/#reading-signed-16-bit-integer","title":"Reading Signed 16-bit Integer","text":"<pre><code>byte[] data = { 0x01, 0x00 };  // Represents the number 1 in little endian format.\nfixed (byte* ptr = data)\n{\nvar reader = new LittleEndianReader(ptr);\nshort value = reader.ReadShort();\nConsole.WriteLine(value); // Outputs: 1\n}\n</code></pre>"},{"location":"Library/Utilities/LittleEndianReader/#reading-unsigned-32-bit-integer-at-specific-offset","title":"Reading Unsigned 32-bit Integer at Specific Offset","text":"<pre><code>byte[] data = { 0x01, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00 };  // Represents the numbers 1 and 2 in little endian format.\nfixed (byte* ptr = data)\n{\nvar reader = new LittleEndianReader(ptr);\nuint value = reader.ReadUIntAtOffset(4);\nConsole.WriteLine(value);  // Outputs: 2\n}\n</code></pre>"},{"location":"Library/Utilities/LittleEndianReader/#reading-signed-64-bit-integer-at-specific-offset","title":"Reading Signed 64-bit Integer at Specific Offset","text":"<pre><code>byte[] data = { 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00 };  // Represents the numbers 1 and 2 in little endian format.\nfixed (byte* ptr = data)\n{\nvar reader = new LittleEndianReader(ptr);\nlong value = reader.ReadLongAtOffset(8);\nConsole.WriteLine(value);  // Outputs: 2\n}\n</code></pre>"},{"location":"Library/Utilities/LittleEndianReader/#advancing-the-pointer","title":"Advancing the Pointer","text":"<pre><code>byte[] data = { 0x01, 0x00, 0x02, 0x00 };  // Represents the numbers 1 and 2 in little endian format.\nfixed (byte* ptr = data)\n{\nvar reader = new LittleEndianReader(ptr);\nreader.Seek(2);  // Skip the first number.\nshort value = reader.ReadShort();\nConsole.WriteLine(value);  // Outputs: 2\n}\n</code></pre>"},{"location":"Library/Utilities/LittleEndianWriter/","title":"LittleEndianWriter","text":"<p>The <code>LittleEndianWriter</code> is a utility structure for writing to a pointer in Little Endian format. It offers various methods to write different types of data to the pointer and automatically advances the pointer after each write.</p>"},{"location":"Library/Utilities/LittleEndianWriter/#properties","title":"Properties","text":"<ul> <li><code>Ptr</code>: The current pointer being written to.</li> </ul>"},{"location":"Library/Utilities/LittleEndianWriter/#constructor","title":"Constructor","text":"<ul> <li><code>LittleEndianWriter(byte* ptr)</code>: Creates a <code>LittleEndianWriter</code> that wraps around a pointer for writing data in Little Endian format.</li> </ul>"},{"location":"Library/Utilities/LittleEndianWriter/#methods","title":"Methods","text":""},{"location":"Library/Utilities/LittleEndianWriter/#write","title":"Write","text":"<p>Writes a value to and advances the pointer.</p> <pre><code>public void Write(short value)\npublic void Write(ushort value)\npublic void Write(uint value)\npublic void Write(int value)\npublic void Write(long value)\npublic void Write(ulong value)\npublic void Write(Span&lt;byte&gt; data)\n</code></pre>"},{"location":"Library/Utilities/LittleEndianWriter/#writeatoffset","title":"WriteAtOffset","text":"<p>Writes a value to the specified offset without advancing the pointer.</p> <pre><code>public void WriteAtOffset(short value, int offset)\npublic void WriteAtOffset(int value, int offset)\npublic void WriteAtOffset(long value, int offset)\npublic void WriteAtOffset(ulong value, int offset)\n</code></pre>"},{"location":"Library/Utilities/LittleEndianWriter/#seek","title":"Seek","text":"<p>Advances the stream by a specified number of bytes.</p> <pre><code>public void Seek(int offset)\n</code></pre>"},{"location":"Library/Utilities/LittleEndianWriter/#about-the-offset-methods","title":"About the Offset Methods","text":"<p>The <code>LittleEndianWriter</code> struct provides the method <code>WriteAtOffset</code> that can be used to write to an offset of the current pointer without advancing the pointer itself.</p> <p>These methods offer some minor performance advantages.</p>"},{"location":"Library/Utilities/LittleEndianWriter/#improved-pipelining","title":"Improved Pipelining","text":"<p>By reducing the dependency of future instructions on earlier instructions, these offset methods allow for better pipelining. For example, a future read operation does not need to wait for the <code>Ptr</code> value to be updated from a previous operation.</p>"},{"location":"Library/Utilities/LittleEndianWriter/#jit-optimization","title":"JIT Optimization","text":"<p>The Just-In-Time (JIT) compiler can recognize when the <code>offset</code> parameters are specified as constants and can optimize the instructions accordingly. This can lead to more efficient code execution.</p> <pre><code>writer.WriteAtOffset(Hash, 0);\nwriter.WriteAtOffset((int)DecompressedSize, 8);\nwriter.WriteAtOffset(new OffsetPathIndexTuple(DecompressedBlockOffset, FilePathIndex, FirstBlockIndex).Data, 12);\nwriter.Seek(NativeFileEntryV0.SizeBytes);\n</code></pre> <p>Because write on <code>line 1</code>, does not depend on modified pointer after <code>line 0</code>, execution is faster, as the CPU can  better pipeline the instructions as there is no dependency on the ptr result of the previous method call.</p>"},{"location":"Library/Utilities/LittleEndianWriter/#examples","title":"Examples","text":""},{"location":"Library/Utilities/LittleEndianWriter/#writing-an-integer-to-the-pointer","title":"Writing an Integer to The Pointer","text":"<pre><code>byte[] data = new byte[4];\nfixed (byte* ptr = data)\n{\nvar writer = new LittleEndianWriter(ptr);\nwriter.Write(42); // Writes the integer 42 to the pointer in Little Endian format, and advances.\n}\n</code></pre>"},{"location":"Library/Utilities/LittleEndianWriter/#writing-a-short-to-the-pointer-at-specific-offset","title":"Writing a Short to The Pointer at Specific Offset","text":"<pre><code>byte[] data = new byte[4];\nfixed (byte* ptr = data)\n{\nvar writer = new LittleEndianWriter(ptr);\nwriter.WriteAtOffset((short)1234, 2); // Writes the short 1234 to the pointer at offset 2 in Little Endian format.\n}\n</code></pre>"},{"location":"Library/Utilities/LittleEndianWriter/#advancing-the-pointer","title":"Advancing the Pointer","text":"<pre><code>byte[] data = new byte[12];\nfixed (byte* ptr = data)\n{\nvar writer = new LittleEndianWriter(ptr);\nwriter.Write(42); // Writes the integer 42 to the pointer in Little Endian format, and advances.\nwriter.Seek(4); // Advances the pointer by 4 bytes.\nwriter.Write(84); // Writes the integer 84 to the new pointer position in Little Endian format, and advances.\n}\n</code></pre>"},{"location":"Nexus/Readme/","title":"Readme","text":"<p>Please visit the documentation site for usage instructions &amp; more.</p>"},{"location":"Nexus/Pages/","title":"Index","text":"The Nexus MkDocs Theme      A Theme for MkDocs Material.          That resembles the Future look of NexusMods."},{"location":"Nexus/Pages/#about","title":"About","text":"<p>This it the NexusMods theme for Material-MkDocs, inspired by the look of Next,  the future iteration of the NexusMods site.  </p> <p>The overall wiki theme should look fairly close to the actual site appearance.</p>"},{"location":"Nexus/Pages/#usage","title":"Usage","text":"<p>Info</p> <p>Coming Soon.</p>"},{"location":"Nexus/Pages/#technical-questions","title":"Technical Questions","text":"<p>If you have questions/bug reports/etc. feel free to Open an Issue.</p> <p>Happy Documenting \ud83e\udde1</p>"},{"location":"Nexus/Pages/contributing/","title":"Contributing to the Wiki: Locally","text":"<p>Info</p> <p>This page shows you how to contribute to any documentation page or wiki  based on this template.</p>"},{"location":"Nexus/Pages/contributing/#tutorial","title":"Tutorial","text":"<p>You should learn the basics of <code>git</code>, an easy way is to give GitHub Desktop (Tutorial) a go. It's only 15 minutes \ud83d\ude00.</p> <ol> <li>Create a GitHub account.</li> <li> <p>Fork this repository:</p> <p></p> <p>This will create a copy of the repository on your own user account, which you will be able to edit.</p> </li> <li> <p>Clone this repository.</p> <p>For example, using GitHub Desktop: </p> </li> <li> <p>Make changes inside the <code>docs</code> folder.</p> <p></p> <p>Consider using a Markdown Cheat Sheet if you are new to markdown.</p> <p>I recommend using a markdown editor such as <code>Typora</code>. Personally I just work from inside <code>Rider</code>.  </p> </li> <li> <p>Commit the changes and push to GitHub.</p> </li> <li> <p>Open a <code>Pull Request</code>.</p> <p></p> <p>Opening a <code>Pull Request</code> will allow us to review your changes before adding them with the main official page. If everything's good, we'll hit the merge button and add your changes to the official repository.</p> </li> </ol>"},{"location":"Nexus/Pages/contributing/#website-live-preview","title":"Website Live Preview","text":"<p>If you are working on the wiki locally, you can generate a live preview the full website. Here's a quick guide of how you could do it from your <code>command prompt</code> (cmd).</p> <ol> <li> <p>Install Python 3</p> <p>If you have <code>winget</code> installed, or Windows 11, you can do this from the command prompt. <pre><code>winget install Python.Python.3\n</code></pre></p> <p>Otherwise download Python 3 from the official website or package manager.</p> </li> <li> <p>Install Material for MkDocs and Plugins (Python package)     <pre><code># Restart your command prompt before running this command.\npip install mkdocs-material\npip install mkdocs-redirects\n</code></pre></p> </li> <li> <p>Open a command prompt in the folder containing <code>mkdocs.yml</code>. and run the site locally.     <pre><code># Move to project folder.\ncd &lt;Replace this with full path to folder containing `mkdocs.yml`&gt;\nmkdocs serve\n</code></pre></p> <p></p> <p>Copy the address to your web browser and enjoy the live preview; any changes you save will be shown instantly.</p> </li> </ol>"},{"location":"Nexus/Pages/testing-zone/","title":"Testing Zone","text":"<p>Info</p> <p>This is a dummy page with various Material MkDocs controls and features scattered throughout for testing.</p>"},{"location":"Nexus/Pages/testing-zone/#custom-admonitions","title":"Custom Admonitions","text":"<p>Nexus Admonition</p> <p>An admonition featuring a Nexus logo. My source is in Stylesheets/extra.css as <code>Custom 'nexus' admonition</code>.  </p> <p>Heart Admonition</p> <p>An admonition featuring a heart; because we want to contribute back to the open source community. My source is in Stylesheets/extra.css as <code>Custom 'nexus heart' admonition</code>.  </p>"},{"location":"Nexus/Pages/testing-zone/#mermaid-diagram","title":"Mermaid Diagram","text":"<p>Flowchart (Source: Nexus Archive Library):  </p> <pre><code>flowchart TD\n    subgraph Block 2\n        BigFile1.bin\n    end\n\n    subgraph Block 1\n        BigFile0.bin\n    end\n\n    subgraph Block 0\n        ModConfig.json -.-&gt; Updates.json \n        Updates.json -.-&gt; more[\"... more .json files\"]        \n    end</code></pre> <p>Sequence Diagram (Source: Reloaded3 Specification):  </p> <pre><code>sequenceDiagram\n\n    % Define Items\n    participant Mod Loader\n    participant Virtual FileSystem (VFS)\n    participant CRI CPK Archive Support\n    participant Persona 5 Royal Support\n    participant Joker Costume\n\n    % Define Actions\n    Mod Loader-&gt;&gt;Persona 5 Royal Support: Load Mod\n    Persona 5 Royal Support-&gt;&gt;Mod Loader: Request CRI CPK Archive Support API\n    Mod Loader-&gt;&gt;Persona 5 Royal Support: Receive CRI CPK Archive Support Instance\n\n    Mod Loader-&gt;&gt;Joker Costume: Load Mod\n    Mod Loader--&gt;Persona 5 Royal Support: Notification: 'Loaded Joker Costume'\n    Persona 5 Royal Support-&gt;&gt;CRI CPK Archive Support: Add Files from 'Joker Costume' to CPK Archive (via API)</code></pre> <p>State Diagram (Source: Mermaid Docs):  </p> <pre><code>stateDiagram-v2\n    [*] --&gt; Still\n    Still --&gt; [*]\n\n    Still --&gt; Moving\n    Moving --&gt; Still\n    Moving --&gt; Crash\n    Crash --&gt; [*]</code></pre> <p>Class Diagram (Arbitrary)</p> <pre><code>classDiagram\n    class Animal\n    `NexusMobile\u2122` &lt;|-- Car</code></pre> <p>Note</p> <p>At time of writing, version of Mermaid is a bit outdated here; and other diagrams might not render correctly (even on unmodified theme); thus certain diagrams have been omitted from here.</p>"},{"location":"Nexus/Pages/testing-zone/#code-block","title":"Code Block","text":"<p>Snippet from C# version of Sewer's Virtual FileSystem (VFS):</p> <pre><code>/// &lt;summary&gt;\n/// Tries to get files for a specific folder, assuming the input path is already in upper case.\n/// &lt;/summary&gt;\n/// &lt;param name=\"folderPath\"&gt;The folder to find. Already lowercase.&lt;/param&gt;\n/// &lt;param name=\"value\"&gt;The returned folder instance.&lt;/param&gt;\n/// &lt;returns&gt;True if found, else false.&lt;/returns&gt;\n[MethodImpl(MethodImplOptions.AggressiveInlining)]\npublic bool TryGetFolderUpper(ReadOnlySpan&lt;char&gt; folderPath, out SpanOfCharDict&lt;TTarget&gt; value)\n{\n// Must be O(1)\nvalue = default!;        // Compare equality.\n// Note to devs: Do not invert branches, we optimise for hot paths here.\nif (folderPath.StartsWith(Prefix))\n{\n// Check for subfolder in branchless way.\n// In CLR, bool is length 1, so conversion to byte should be safe.\n// Even suppose it is not; as long as code is little endian; truncating int/4 bytes to byte still results \n// in correct answer.\nvar hasSubfolder = Prefix.Length != folderPath.Length;\nvar hasSubfolderByte = Unsafe.As&lt;bool, byte&gt;(ref hasSubfolder);\nvar nextFolder = folderPath.SliceFast(Prefix.Length + hasSubfolderByte);\n\nreturn SubfolderToFiles.TryGetValue(nextFolder, out value!);\n}\n\nreturn false;\n}\n</code></pre> <p>Something more number heavy, Fast Inverse Square Root from Quake III Arena (unmodified). <pre><code>float Q_rsqrt( float number )\n{\nlong i;\nfloat x2, y;\nconst float threehalfs = 1.5F;\n\nx2 = number * 0.5F;\ny  = number;\ni  = * ( long * ) &amp;y;                       // evil floating point bit level hacking\ni  = 0x5f3759df - ( i &gt;&gt; 1 );               // what the fuck? \ny  = * ( float * ) &amp;i;\ny  = y * ( threehalfs - ( x2 * y * y ) );   // 1st iteration\n//  y  = y * ( threehalfs - ( x2 * y * y ) );   // 2nd iteration, this can be removed\n\nreturn y;\n}\n</code></pre></p>"},{"location":"Nexus/Pages/testing-zone/#default-admonitions","title":"Default Admonitions","text":"<p>Note</p> <p>Test</p> <p>Abstract</p> <p>Test</p> <p>Info</p> <p>Test</p> <p>Tip</p> <p>Test</p> <p>Success</p> <p>Test</p> <p>Question</p> <p>Test</p> <p>Warning</p> <p>Test</p> <p>Failure</p> <p>Test</p> <p>Danger</p> <p>Test</p> <p>Bug</p> <p>Test</p> <p>Example</p> <p>Test</p> <p>Quote</p> <p>Test</p>"},{"location":"Nexus/Pages/testing-zone/#tables","title":"Tables","text":"Method Description <code>GET</code>      Fetch resource <code>PUT</code>  Update resource <code>DELETE</code>      Delete resource"},{"location":"Nexus/docs/Pages/","title":"Index","text":"The Nexus MkDocs Theme      A Theme for MkDocs Material.          That resembles the Future look of NexusMods."},{"location":"Nexus/docs/Pages/#about","title":"About","text":"<p>This it the NexusMods theme for Material-MkDocs, inspired by the look of Next,  the future iteration of the NexusMods site.  </p> <p>The overall wiki theme should look fairly close to the actual site appearance.</p>"},{"location":"Nexus/docs/Pages/#usage","title":"Usage","text":"<p>Info</p> <p>Coming Soon.</p>"},{"location":"Nexus/docs/Pages/#technical-questions","title":"Technical Questions","text":"<p>If you have questions/bug reports/etc. feel free to Open an Issue.</p> <p>Happy Documenting \ud83e\udde1</p>"},{"location":"Nexus/docs/Pages/contributing/","title":"Contributing to the Wiki: Locally","text":"<p>Info</p> <p>This page shows you how to contribute to any documentation page or wiki  based on this template.</p>"},{"location":"Nexus/docs/Pages/contributing/#tutorial","title":"Tutorial","text":"<p>You should learn the basics of <code>git</code>, an easy way is to give GitHub Desktop (Tutorial) a go. It's only 15 minutes \ud83d\ude00.</p> <ol> <li>Create a GitHub account.</li> <li> <p>Fork this repository:</p> <p></p> <p>This will create a copy of the repository on your own user account, which you will be able to edit.</p> </li> <li> <p>Clone this repository.</p> <p>For example, using GitHub Desktop: </p> </li> <li> <p>Make changes inside the <code>docs</code> folder.</p> <p></p> <p>Consider using a Markdown Cheat Sheet if you are new to markdown.</p> <p>I recommend using a markdown editor such as <code>Typora</code>. Personally I just work from inside <code>Rider</code>.  </p> </li> <li> <p>Commit the changes and push to GitHub.</p> </li> <li> <p>Open a <code>Pull Request</code>.</p> <p></p> <p>Opening a <code>Pull Request</code> will allow us to review your changes before adding them with the main official page. If everything's good, we'll hit the merge button and add your changes to the official repository.</p> </li> </ol>"},{"location":"Nexus/docs/Pages/contributing/#website-live-preview","title":"Website Live Preview","text":"<p>If you are working on the wiki locally, you can generate a live preview the full website. Here's a quick guide of how you could do it from your <code>command prompt</code> (cmd).</p> <ol> <li> <p>Install Python 3</p> <p>If you have <code>winget</code> installed, or Windows 11, you can do this from the command prompt. <pre><code>winget install Python.Python.3\n</code></pre></p> <p>Otherwise download Python 3 from the official website or package manager.</p> </li> <li> <p>Install Material for MkDocs and Plugins (Python package)     <pre><code># Restart your command prompt before running this command.\npip install mkdocs-material\npip install mkdocs-redirects\n</code></pre></p> </li> <li> <p>Open a command prompt in the folder containing <code>mkdocs.yml</code>. and run the site locally.     <pre><code># Move to project folder.\ncd &lt;Replace this with full path to folder containing `mkdocs.yml`&gt;\nmkdocs serve\n</code></pre></p> <p></p> <p>Copy the address to your web browser and enjoy the live preview; any changes you save will be shown instantly.</p> </li> </ol>"},{"location":"Nexus/docs/Pages/testing-zone/","title":"Testing Zone","text":"<p>Info</p> <p>This is a dummy page with various Material MkDocs controls and features scattered throughout for testing.</p>"},{"location":"Nexus/docs/Pages/testing-zone/#custom-admonitions","title":"Custom Admonitions","text":"<p>Nexus Admonition</p> <p>An admonition featuring a Nexus logo. My source is in Stylesheets/extra.css as <code>Custom 'nexus' admonition</code>.  </p> <p>Heart Admonition</p> <p>An admonition featuring a heart; because we want to contribute back to the open source community. My source is in Stylesheets/extra.css as <code>Custom 'nexus heart' admonition</code>.  </p>"},{"location":"Nexus/docs/Pages/testing-zone/#mermaid-diagram","title":"Mermaid Diagram","text":"<p>Flowchart (Source: Nexus Archive Library):  </p> <pre><code>flowchart TD\n    subgraph Block 2\n        BigFile1.bin\n    end\n\n    subgraph Block 1\n        BigFile0.bin\n    end\n\n    subgraph Block 0\n        ModConfig.json -.-&gt; Updates.json \n        Updates.json -.-&gt; more[\"... more .json files\"]        \n    end</code></pre> <p>Sequence Diagram (Source: Reloaded3 Specification):  </p> <pre><code>sequenceDiagram\n\n    % Define Items\n    participant Mod Loader\n    participant Virtual FileSystem (VFS)\n    participant CRI CPK Archive Support\n    participant Persona 5 Royal Support\n    participant Joker Costume\n\n    % Define Actions\n    Mod Loader-&gt;&gt;Persona 5 Royal Support: Load Mod\n    Persona 5 Royal Support-&gt;&gt;Mod Loader: Request CRI CPK Archive Support API\n    Mod Loader-&gt;&gt;Persona 5 Royal Support: Receive CRI CPK Archive Support Instance\n\n    Mod Loader-&gt;&gt;Joker Costume: Load Mod\n    Mod Loader--&gt;Persona 5 Royal Support: Notification: 'Loaded Joker Costume'\n    Persona 5 Royal Support-&gt;&gt;CRI CPK Archive Support: Add Files from 'Joker Costume' to CPK Archive (via API)</code></pre> <p>State Diagram (Source: Mermaid Docs):  </p> <pre><code>stateDiagram-v2\n    [*] --&gt; Still\n    Still --&gt; [*]\n\n    Still --&gt; Moving\n    Moving --&gt; Still\n    Moving --&gt; Crash\n    Crash --&gt; [*]</code></pre> <p>Class Diagram (Arbitrary)</p> <pre><code>classDiagram\n    class Animal\n    `NexusMobile\u2122` &lt;|-- Car</code></pre> <p>Note</p> <p>At time of writing, version of Mermaid is a bit outdated here; and other diagrams might not render correctly (even on unmodified theme); thus certain diagrams have been omitted from here.</p>"},{"location":"Nexus/docs/Pages/testing-zone/#code-block","title":"Code Block","text":"<p>Snippet from C# version of Sewer's Virtual FileSystem (VFS):</p> <pre><code>/// &lt;summary&gt;\n/// Tries to get files for a specific folder, assuming the input path is already in upper case.\n/// &lt;/summary&gt;\n/// &lt;param name=\"folderPath\"&gt;The folder to find. Already lowercase.&lt;/param&gt;\n/// &lt;param name=\"value\"&gt;The returned folder instance.&lt;/param&gt;\n/// &lt;returns&gt;True if found, else false.&lt;/returns&gt;\n[MethodImpl(MethodImplOptions.AggressiveInlining)]\npublic bool TryGetFolderUpper(ReadOnlySpan&lt;char&gt; folderPath, out SpanOfCharDict&lt;TTarget&gt; value)\n{\n// Must be O(1)\nvalue = default!;        // Compare equality.\n// Note to devs: Do not invert branches, we optimise for hot paths here.\nif (folderPath.StartsWith(Prefix))\n{\n// Check for subfolder in branchless way.\n// In CLR, bool is length 1, so conversion to byte should be safe.\n// Even suppose it is not; as long as code is little endian; truncating int/4 bytes to byte still results \n// in correct answer.\nvar hasSubfolder = Prefix.Length != folderPath.Length;\nvar hasSubfolderByte = Unsafe.As&lt;bool, byte&gt;(ref hasSubfolder);\nvar nextFolder = folderPath.SliceFast(Prefix.Length + hasSubfolderByte);\n\nreturn SubfolderToFiles.TryGetValue(nextFolder, out value!);\n}\n\nreturn false;\n}\n</code></pre> <p>Something more number heavy, Fast Inverse Square Root from Quake III Arena (unmodified). <pre><code>float Q_rsqrt( float number )\n{\nlong i;\nfloat x2, y;\nconst float threehalfs = 1.5F;\n\nx2 = number * 0.5F;\ny  = number;\ni  = * ( long * ) &amp;y;                       // evil floating point bit level hacking\ni  = 0x5f3759df - ( i &gt;&gt; 1 );               // what the fuck? \ny  = * ( float * ) &amp;i;\ny  = y * ( threehalfs - ( x2 * y * y ) );   // 1st iteration\n//  y  = y * ( threehalfs - ( x2 * y * y ) );   // 2nd iteration, this can be removed\n\nreturn y;\n}\n</code></pre></p>"},{"location":"Nexus/docs/Pages/testing-zone/#default-admonitions","title":"Default Admonitions","text":"<p>Note</p> <p>Test</p> <p>Abstract</p> <p>Test</p> <p>Info</p> <p>Test</p> <p>Tip</p> <p>Test</p> <p>Success</p> <p>Test</p> <p>Question</p> <p>Test</p> <p>Warning</p> <p>Test</p> <p>Failure</p> <p>Test</p> <p>Danger</p> <p>Test</p> <p>Bug</p> <p>Test</p> <p>Example</p> <p>Test</p> <p>Quote</p> <p>Test</p>"},{"location":"Nexus/docs/Pages/testing-zone/#tables","title":"Tables","text":"Method Description <code>GET</code>      Fetch resource <code>PUT</code>  Update resource <code>DELETE</code>      Delete resource"},{"location":"Specification/File-Header/","title":"File Header","text":"<p>8 bytes:</p> <ul> <li><code>u8[4]</code> Magic (<code>\"NXUS\"</code>)</li> <li><code>u4</code> Version/Variant</li> <li><code>u4</code> BlockSize</li> <li><code>u3</code> Large File Chunk Size</li> <li><code>u13</code> HeaderPageCount</li> <li><code>u8</code> Feature Flags</li> </ul>"},{"location":"Specification/File-Header/#versionvariant","title":"Version/Variant","text":"<p>Size: <code>4 bits</code> (0-15)</p> <ul> <li> <p><code>0</code>:</p> <ul> <li>Most common variant covering 99.99% of cases.</li> <li>20 byte FileEntry w/ <code>u32</code> Size</li> <li>Up to 4GB (2^32) per file and 1 million files.</li> </ul> </li> <li> <p><code>1</code>:</p> <ul> <li>Variant for archives with large files &gt;= 4GB size.</li> <li>24 byte FileEntry w/ <code>u64</code> Size</li> <li>2^64 bytes per file and 1 million files.</li> </ul> </li> </ul> <p>Remaining bits reserved for possible future revisions. Limitation of 1 million files is inferred from FileEntry -&gt; FilePathIndex.</p>"},{"location":"Specification/File-Header/#block-size","title":"Block Size","text":"<p>Stored so the decompressor knows how big each block is.</p> <p>Size: <code>4 bits</code>, but restricted (0-11) due to Table of Contents File Entries. Parsed as <code>(32768 &lt;&lt; blockSize) - 1</code>.</p> <p>i.e. BlockSize = 11 is <code>67108863</code> (i.e. <code>64MiB - 1</code> or <code>2^26 - 1</code>).  </p> <p>We remove -1 from the value to avoid collisions with Chunk Size.  </p>"},{"location":"Specification/File-Header/#large-file-chunk-size","title":"Large File Chunk Size","text":"<p>Tip</p> <p>Large files are split into several chunks during packing to improve compression speeds at minimal compression ratio loss.  </p> <p>Stored so the decompressor knows how many chunks a file is split into; and how much memory to allocate. Also limits memory use on 4+GB archives.  </p> <p>Size: <code>3 bits</code>, (0-7). Parsed as <code>4194304 &lt;&lt; chunkSize</code>.  </p> <p>i.e. ChunkSize = 7 is <code>536870912</code> (512MiB, i.e. 2^29).  </p> <p>Note</p> <p>Please do not confuse 'block' and 'chunk'. Blocks segment the compressed data. Chunks segment a file.</p> <p>Warning</p> <p>Chunk size should always exceed Block size. Implementation of archiver can either return error or enforce this automatically.</p>"},{"location":"Specification/File-Header/#header-page-count","title":"Header Page Count","text":"<p>Number of 4K memory pages required to store this header and the Table of Contents (incl. compressed StringPool).  </p> <p>Size: <code>13 bits</code>, (0-8191). Max size of 32MiB.  </p> <pre><code>return 4096 * tocPageCount;\n</code></pre> <p>Tip</p> <p>As a rough reference, StringPool [main memory consumer] of (150+) games (180k files) on Sewer's PC used up 3.3MB uncompressed, 660K compressed.</p> <p>Note</p> <p>The headers are padded to the number of bytes stored here.</p>"},{"location":"Specification/File-Header/#feature-flags","title":"Feature Flags","text":"<p>Info</p> <p>This is a section for flags which enable/disable additional features. (e.g. Storing additional file metadata)</p> <p>This section is reserved and currently unused.</p>"},{"location":"Specification/Implementation-Details/","title":"Implementation Details","text":"<p>Info</p> <p>This page contains guidance for people implementing their own libraries for working with <code>.nx</code> files. It is not a step by step guide, just some guidelines.  </p>"},{"location":"Specification/Implementation-Details/#use-memory-maps","title":"Use Memory Maps","text":"<p>Tip</p> <p>When possible, work with memory mapped files.</p> <ul> <li>A system call is orders of magnitude slower than change to a program's local memory.   </li> <li>It can avoid data copies, as it can map to kernel's page (file) cache; meaning copies of data isn't unnecessarily made in user space.  </li> </ul>"},{"location":"Specification/Implementation-Details/#parallel-decompression","title":"Parallel Decompression","text":"<p>Info</p> <p>Files are decompressed in parallel by decompressing multiple blocks in separate threads/tasks.</p> <p>The decoding logic should assigns each block to a given thread; and then each thread performs the following action(s):  </p> <ul> <li>Allocate and <code>mmap</code> output files in advance.  </li> <li>Decompress relevant data into output files.  </li> <li>Flush to disk every file when all data has been written.  </li> </ul> <p>Most compression algorithms accept <code>Span&lt;byte&gt;</code>; and in cases where we might need to do native interop; we of course have pointers.</p>"},{"location":"Specification/Implementation-Details/#parallel-compression","title":"Parallel Compression","text":"<p>Info</p> <p>Compression process involves grouping the files into blocks, then compressing the blocks in parallel.</p> <p>To do this, we will perform the following steps:  </p> <ul> <li>Files are sorted by size. (optimize for blocks)  </li> <li>Files are then grouped by extension. (optimize for ratio) [while preserving sorting]  </li> <li>These groups are chunked into SOLID blocks (and huge files into Chunk blocks).  </li> <li>We assign the groups to individual blocks using a task scheduler; which is simply a ThreadPool that will pick up tasks in the order they are submitted.  </li> </ul> <p>Note</p> <p>Grouping files by extension (equivalent to 7zip <code>qs</code> parameter) improves compression ratio, as data between different files of same type is likely to be similar (e.g. two text files).  </p>"},{"location":"Specification/Implementation-Details/#choosing-compression-implementation","title":"Choosing Compression Implementation","text":"<p>Tip</p> <p>There is an important tradeoff between size and speed to be made,  especially for more real-time cases like Nexus Mods App where downloaded mods are recompressed on download. </p> <p>The appropriate approach depends on your input data and use case; below are some general tips.</p> <ul> <li> <p>For repacking downloaded files from the web; prefer faster compression approaches.  </p> <ul> <li>Prefer <code>lz4 -12</code> or <code>zstd -16</code> (depending on CPU, estimate power by thread count).  </li> <li>Can't have the user wait too long...  </li> <li>We only use highest levels e.g. <code>zstd -22</code> when 'publishing' (uploading) to web.  </li> </ul> </li> <li> <p>Files which we know are not compressible are assigned <code>copy</code> as compression strategy in their blocks.  </p> <ul> <li>We provide a mechanism to feed this info from outside the library.  </li> </ul> </li> <li> <p>Prefer ZStd for large files.  </p> </li> </ul>"},{"location":"Specification/Implementation-Details/#repackingappending-files","title":"Repacking/Appending Files","text":"<p>Speed of this operation depends on SOLID block size, but in most cases should be reasonably fast. This is because non-SOLID blocks used for big files can be copied verbatim.</p> <p>Updating the ToC is inexpensive.</p>"},{"location":"Specification/Overview/","title":"Format Specification","text":"<p>Note</p> <p>This is a semi-SOLID archive format for storing game mod content; intended to double up as a packaging format for uploading mods.</p> <p>It has the following properties:  </p> <ul> <li>Files under Block Size are SOLID Compressed.  </li> <li>Files above Block Size are non-SOLID Compressed.  </li> <li>Variable Block Size.  </li> <li>Stores File Hashes Within.  </li> <li>Huge Files Split into Chunks for Faster (De)compression.  </li> <li>TOC in-front.  </li> </ul> <p>We use SOLID compression to bundle up small files together, while keeping the large files as separate compressed blobs. All files are entirely contained within a slice of a given block.  </p> <pre><code>flowchart TD\n    subgraph Block 2\n        BigFile1.bin\n    end\n\n    subgraph Block 1\n        BigFile0.bin\n    end\n\n    subgraph Block 0\n        ModConfig.json -.-&gt; Updates.json\n        Updates.json -.-&gt; more[\"... more .json files\"]        \n    end</code></pre> <p>Offsets of each block is stored in header, therefore large files can be completely skipped during the extract operation if a small file is all that is needed.</p> <p>Note</p> <p>This format is optimized for transferring and unpacking files; editing existing archives might lead to sub-optimal performance.</p>"},{"location":"Specification/Overview/#overall-format-layout","title":"Overall Format Layout","text":"<p>The overall file is structured in this order:  </p> <pre><code>| Header + TOC | Block 1 | Block 2 | ... | Block N |\n</code></pre> <p>All sections (indicated by <code>|</code>) are 4096 aligned to match physical sector size of modern drives and page granularity.  </p> <p>Field sizes used below are similar to Rust notation; with some custom types e.g. </p> <ul> <li><code>u8</code>: Unsigned 8 bits.  </li> <li><code>i8</code>: Signed 8 bits.  </li> <li><code>u4</code>: 4 bits.  </li> <li><code>u32/u64</code>: 4 Bytes or 8 Bytes (depending on variant).  </li> </ul> <p>Assume any bit packed values are sequential, i.e. if <code>u4</code> then <code>u4</code> is specified, first <code>u4</code> is the upper 4 bits.  </p> <p>All packed fields are <code>little-endian</code>; and written out when total number of bits aligns with a power of 2.  </p> <ul> <li><code>u6</code> + <code>u12</code> is 2 bytes <code>little-endian</code> </li> <li><code>u15</code> + <code>u17</code> is 4 bytes <code>little-endian</code> </li> <li><code>u26</code> + <code>u22</code> + <code>u16</code> is 8 bytes <code>little-endian</code> </li> <li><code>u6</code> + <code>u11</code> + <code>u17</code> is 4 bytes <code>little-endian</code>, not 2+2 </li> </ul>"},{"location":"Specification/Overview/#use-as-packaging-format","title":"Use as Packaging Format","text":"<p>Tip</p> <p>Inclusion of hash for each file has some nice benefits.</p> <ul> <li> <p>Can do partial download to upgrade from older version of mod.  </p> <ul> <li>We can download Table of Contents only, compare hashes.  </li> <li>Then only download the chunks we need to decompress our needed data.  </li> <li>Inspired by MSIX and certain Linux package formats.  </li> </ul> </li> <li> <p>Certain applications like Nexus Mods App can avoid re-hashing files.  </p> </li> </ul>"},{"location":"Specification/Overview/#previewing-the-format","title":"Previewing the Format","text":"<p>Info</p> <p>For people wishing to study the format, or debug it, a 010-Editor template  is available for usage 010 Template.  </p> <p>Hit <code>Templates -&gt; Open Template</code> and then the big play button. Then you'll be able to browse the format in 'Variables' window.  </p> <p>Alternatively, contributions are welcome if anyone wants to make a Kaitai Struct variation \ud83d\udc9c.</p>"},{"location":"Specification/Table-Of-Contents/","title":"Table of Contents (TOC)","text":"<ul> <li><code>u32</code>: FileCount [limited to 1 million due to FilePathIndex]</li> <li><code>u18</code>: BlockCount</li> <li><code>u12</code>: TablePadding</li> <li><code>u2</code>: Reserved</li> <li><code>FileEntry[FileCount]</code><ul> <li><code>u64</code>: FileHash (xxHash64)</li> <li><code>u32/u64</code>: DecompressedSize</li> <li><code>u26</code>: DecompressedBlockOffset [limits max block size]</li> <li><code>u20</code>: FilePathIndex (in StringPool) [limits max file count]</li> <li><code>u18</code>: FirstBlockIndex</li> </ul> </li> <li>Blocks[BlockCount]<ul> <li><code>u29</code> CompressedBlockSize</li> <li><code>u3</code> Compression</li> </ul> </li> <li>StringPool<ul> <li><code>RawCompressedData...</code></li> </ul> </li> </ul>"},{"location":"Specification/Table-Of-Contents/#file-entries","title":"File Entries","text":"<p>Use known fixed size and are 4 byte aligned to improve parsing speed; size 20-24 bytes per item depending on variant.</p>"},{"location":"Specification/Table-Of-Contents/#implicit-property-chunk-count","title":"Implicit Property: Chunk Count","text":"<p>Tip</p> <p>Files exceeding Chunk Size span multiple blocks.</p> <p>Number of blocks used to store the file is calculated as: <code>DecompressedSize</code> / Chunk Size,  and +1 if there is any remainder, i.e. </p> <pre><code>public int GetChunkCount(int chunkSizeBytes)\n{\nvar count = DecompressedSize / (ulong)chunkSizeBytes;\nif (DecompressedSize % (ulong)chunkSizeBytes != 0)\ncount += 1;\n\nreturn (int)count;\n}\n</code></pre> <p>All chunk blocks are stored sequentially.  </p>"},{"location":"Specification/Table-Of-Contents/#blocks","title":"Blocks","text":"<p>Each entry contains raw size of the block; and compression used. This avoids us having to have an offset for each block.</p>"},{"location":"Specification/Table-Of-Contents/#compression","title":"Compression","text":"<p>Size: <code>3 bits</code> (0-7)</p> <ul> <li><code>0</code>: Copy</li> <li><code>1</code>: ZStandard</li> <li><code>2</code>: LZ4</li> <li><code>3-7</code>: Reserved</li> </ul> <p>As we do not store the length of the decompressed data, this must be determined from the compressed block.</p>"},{"location":"Specification/Table-Of-Contents/#table-padding","title":"Table Padding","text":"<p>Info</p> <p>Stores the amount of padding that was applied to the table during serialization.  </p> <p>This is needed to calculate the end position of the String Pool without using more space in ToC.  </p> <p>This value is encoded as:  <pre><code>// FileHeader is just the 8 byte header.\nvar paddingOffset = (tocSize + sizeof(FileHeader)).RoundUp4096() - tocSize;\n</code></pre></p> <p>And decoded as:</p> <pre><code>tocSize = (tocSize + sizeof(FileHeader)).RoundUp4096();\nvar paddingSize = tocSize - paddingOffset;\n</code></pre> <p>This way the decoding logic can work when given either a padded or unpadded size.</p>"},{"location":"Specification/Table-Of-Contents/#string-pool","title":"String Pool","text":"<p>Raw buffer of UTF-8 deduplicated strings of file paths. Each string is null terminated. The strings in this pool are first lexicographically sorted (to group similar paths together); and then compressed using ZStd. As for decompression, size of this pool is unknown until after decompression is done; file header should specify sufficient buffer size.</p> <p>For example a valid (decompressed) pool might look like this: <code>data/textures/cat.png\\0data/textures/dog.png</code></p> <p>String length is determined by searching null terminators. We will determine lengths of all strings ahead of time by scanning for (<code>0x00</code>) using SIMD. No edge cases; <code>0x00</code> is guaranteed null terminator due to nature of UTF-8 encoding.</p> <p>See UTF-8 encoding table:</p> Code point range Byte 1 Byte 2 Byte 3 Byte 4 Code points U+0000 - U+007F 0xxxxxxx 128 U+0080 - U+07FF 110xxxxx 10xxxxxx 1920 U+0800 - U+FFFF 1110xxxx 10xxxxxx 10xxxxxx 61440 U+10000 - U+10FFFF 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx 1048576 <p>When parsing the archive; we decode the StringPool into an array of strings.</p> <p>Note</p> <p>It is possible to make ZSTD dictionaries for individual game directories that would further improve StringPool compression ratios.  </p> <p>This might be added in the future but is currently not planned until additional testing and a backwards compatibility  plan for decompressors missing the relevant dictionaries is decided.</p>"},{"location":"Specification/Table-Of-Contents/#performance-considerations","title":"Performance Considerations","text":"<p>The header + TOC design aim to fit under 4096 bytes when possible. Based on a small 132 Mod, 7 Game Dataset, it is expected that &gt;=90% of mods out there will fit. This is to take advantage of read granularity; more specifically:</p> <ul> <li>Page File Granularity</li> </ul> <p>For our use case where we memory map the file. Memory maps are always aligned to the page size, this is 4KiB on Windows and Linux (by default). Therefore, a 5 KiB file will allocate 8 KiB and thus 3 KiB are wasted.</p> <ul> <li>Unbuffered Disk Read</li> </ul> <p>If you have storage manufactured in the last 10 years, you probably have a physical sector size of 4096 bytes.</p> <pre><code>fsutil fsinfo ntfsinfo c:\n# Bytes Per Physical Sector: 4096\n</code></pre> <p>a.k.a. 'Advanced Format'. This is very convenient (especially since it matches page granularity); as when we open a mapped file (or even just read unbuffered), we can read the exact amount of bytes to get header.</p>"}]}